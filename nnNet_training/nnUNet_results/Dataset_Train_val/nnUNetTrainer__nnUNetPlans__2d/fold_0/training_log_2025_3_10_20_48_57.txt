
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [7, 7], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset_Train_val', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 512, 512], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 115.30154836509529, 'median': 116.0, 'min': 0.0, 'percentile_00_5': 39.0, 'percentile_99_5': 202.0, 'std': 33.93669307531929}}} 
 
2025-03-10 20:48:59.637786: unpacking dataset... 
2025-03-10 20:49:04.013181: unpacking done... 
2025-03-10 20:49:04.013994: do_dummy_2d_data_aug: False 
2025-03-10 20:49:04.020969: Using splits from existing split file: ./nnNet_training/nnUNet_preprocessed/Dataset_Train_val/splits_final.json 
2025-03-10 20:49:04.021909: The split file contains 5 splits. 
2025-03-10 20:49:04.021992: Desired fold for training: 0 
2025-03-10 20:49:04.022058: This split has 800 training and 200 validation cases. 
2025-03-10 20:49:04.041358: Unable to plot network architecture: 
2025-03-10 20:49:04.041525: No module named 'hiddenlayer' 
2025-03-10 20:49:04.051187:  
2025-03-10 20:49:04.051341: Epoch 0 
2025-03-10 20:49:04.051566: Current learning rate: 0.01 
2025-03-10 20:53:34.718231: train_loss 0.0595 
2025-03-10 20:53:34.718530: val_loss -0.0522 
2025-03-10 20:53:34.718614: Pseudo dice [np.float32(0.0)] 
2025-03-10 20:53:34.718708: Epoch time: 270.67 s 
2025-03-10 20:53:34.718777: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-10 20:53:35.910503:  
2025-03-10 20:53:35.910710: Epoch 1 
2025-03-10 20:53:35.910844: Current learning rate: 0.00991 
2025-03-10 20:57:45.919831: train_loss -0.1768 
2025-03-10 20:57:45.920122: val_loss -0.2673 
2025-03-10 20:57:45.920182: Pseudo dice [np.float32(0.3457)] 
2025-03-10 20:57:45.920270: Epoch time: 250.01 s 
2025-03-10 20:57:45.920331: Yayy! New best EMA pseudo Dice: 0.03460000082850456 
2025-03-10 20:57:47.249804:  
2025-03-10 20:57:47.249996: Epoch 2 
2025-03-10 20:57:47.250135: Current learning rate: 0.00982 
2025-03-10 21:01:57.207956: train_loss -0.2872 
2025-03-10 21:01:57.208333: val_loss -0.3236 
2025-03-10 21:01:57.208391: Pseudo dice [np.float32(0.3952)] 
2025-03-10 21:01:57.208533: Epoch time: 249.96 s 
2025-03-10 21:01:57.208605: Yayy! New best EMA pseudo Dice: 0.0706000030040741 
2025-03-10 21:01:58.596907:  
2025-03-10 21:01:58.597111: Epoch 3 
2025-03-10 21:01:58.597232: Current learning rate: 0.00973 
2025-03-10 21:06:08.560107: train_loss -0.3444 
2025-03-10 21:06:08.560399: val_loss -0.343 
2025-03-10 21:06:08.560458: Pseudo dice [np.float32(0.4056)] 
2025-03-10 21:06:08.560538: Epoch time: 249.96 s 
2025-03-10 21:06:08.560599: Yayy! New best EMA pseudo Dice: 0.10409999638795853 
2025-03-10 21:06:10.117574:  
2025-03-10 21:06:10.117758: Epoch 4 
2025-03-10 21:06:10.117889: Current learning rate: 0.00964 
2025-03-10 21:10:20.068884: train_loss -0.3821 
2025-03-10 21:10:20.069187: val_loss -0.3822 
2025-03-10 21:10:20.069246: Pseudo dice [np.float32(0.4407)] 
2025-03-10 21:10:20.069329: Epoch time: 249.95 s 
2025-03-10 21:10:20.069389: Yayy! New best EMA pseudo Dice: 0.13779999315738678 
2025-03-10 21:10:21.479206:  
2025-03-10 21:10:21.479404: Epoch 5 
2025-03-10 21:10:21.479552: Current learning rate: 0.00955 
2025-03-10 21:14:31.334184: train_loss -0.4126 
2025-03-10 21:14:31.334482: val_loss -0.383 
2025-03-10 21:14:31.334542: Pseudo dice [np.float32(0.4467)] 
2025-03-10 21:14:31.334626: Epoch time: 249.86 s 
2025-03-10 21:14:31.334683: Yayy! New best EMA pseudo Dice: 0.16869999468326569 
2025-03-10 21:14:32.649095:  
2025-03-10 21:14:32.649293: Epoch 6 
2025-03-10 21:14:32.649428: Current learning rate: 0.00946 
2025-03-10 21:18:42.664025: train_loss -0.4425 
2025-03-10 21:18:42.664321: val_loss -0.4011 
2025-03-10 21:18:42.664380: Pseudo dice [np.float32(0.4618)] 
2025-03-10 21:18:42.664463: Epoch time: 250.02 s 
2025-03-10 21:18:42.664520: Yayy! New best EMA pseudo Dice: 0.1979999989271164 
2025-03-10 21:18:43.985134:  
2025-03-10 21:18:43.985320: Epoch 7 
2025-03-10 21:18:43.985454: Current learning rate: 0.00937 
2025-03-10 21:22:53.889675: train_loss -0.4666 
2025-03-10 21:22:53.889945: val_loss -0.4407 
2025-03-10 21:22:53.890005: Pseudo dice [np.float32(0.4935)] 
2025-03-10 21:22:53.890086: Epoch time: 249.91 s 
2025-03-10 21:22:53.890143: Yayy! New best EMA pseudo Dice: 0.22750000655651093 
2025-03-10 21:22:55.231141:  
2025-03-10 21:22:55.231317: Epoch 8 
2025-03-10 21:22:55.231443: Current learning rate: 0.00928 
2025-03-10 21:27:05.338887: train_loss -0.4945 
2025-03-10 21:27:05.339258: val_loss -0.4544 
2025-03-10 21:27:05.339319: Pseudo dice [np.float32(0.5108)] 
2025-03-10 21:27:05.339403: Epoch time: 250.11 s 
2025-03-10 21:27:05.339462: Yayy! New best EMA pseudo Dice: 0.25589999556541443 
2025-03-10 21:27:06.687164:  
2025-03-10 21:27:06.687528: Epoch 9 
2025-03-10 21:27:06.687662: Current learning rate: 0.00919 
2025-03-10 21:31:16.765630: train_loss -0.4986 
2025-03-10 21:31:16.765918: val_loss -0.4671 
2025-03-10 21:31:16.765975: Pseudo dice [np.float32(0.5248)] 
2025-03-10 21:31:16.766055: Epoch time: 250.08 s 
2025-03-10 21:31:16.766113: Yayy! New best EMA pseudo Dice: 0.28279998898506165 
2025-03-10 21:31:18.102326:  
2025-03-10 21:31:18.102508: Epoch 10 
2025-03-10 21:31:18.102628: Current learning rate: 0.0091 
2025-03-10 21:35:28.160367: train_loss -0.523 
2025-03-10 21:35:28.160706: val_loss -0.4745 
2025-03-10 21:35:28.160768: Pseudo dice [np.float32(0.5252)] 
2025-03-10 21:35:28.160847: Epoch time: 250.06 s 
2025-03-10 21:35:28.160909: Yayy! New best EMA pseudo Dice: 0.3070000112056732 
2025-03-10 21:35:29.493237:  
2025-03-10 21:35:29.493442: Epoch 11 
2025-03-10 21:35:29.493573: Current learning rate: 0.009 
2025-03-10 21:39:39.636035: train_loss -0.5343 
2025-03-10 21:39:39.636353: val_loss -0.4733 
2025-03-10 21:39:39.636413: Pseudo dice [np.float32(0.5249)] 
2025-03-10 21:39:39.636494: Epoch time: 250.14 s 
2025-03-10 21:39:39.636557: Yayy! New best EMA pseudo Dice: 0.3287999927997589 
2025-03-10 21:39:40.995296:  
2025-03-10 21:39:40.995488: Epoch 12 
2025-03-10 21:39:40.995620: Current learning rate: 0.00891 
2025-03-10 21:43:51.089570: train_loss -0.5634 
2025-03-10 21:43:51.090118: val_loss -0.5019 
2025-03-10 21:43:51.090198: Pseudo dice [np.float32(0.5514)] 
2025-03-10 21:43:51.090348: Epoch time: 250.1 s 
2025-03-10 21:43:51.090415: Yayy! New best EMA pseudo Dice: 0.35109999775886536 
2025-03-10 21:43:52.862785:  
2025-03-10 21:43:52.862948: Epoch 13 
2025-03-10 21:43:52.863053: Current learning rate: 0.00882 
2025-03-10 21:48:02.939588: train_loss -0.568 
2025-03-10 21:48:02.939919: val_loss -0.4829 
2025-03-10 21:48:02.939996: Pseudo dice [np.float32(0.5364)] 
2025-03-10 21:48:02.940095: Epoch time: 250.08 s 
2025-03-10 21:48:02.940154: Yayy! New best EMA pseudo Dice: 0.36959999799728394 
2025-03-10 21:48:04.271307:  
2025-03-10 21:48:04.271471: Epoch 14 
2025-03-10 21:48:04.271578: Current learning rate: 0.00873 
2025-03-10 21:52:14.456578: train_loss -0.5586 
2025-03-10 21:52:14.456847: val_loss -0.455 
2025-03-10 21:52:14.456904: Pseudo dice [np.float32(0.5083)] 
2025-03-10 21:52:14.456987: Epoch time: 250.19 s 
2025-03-10 21:52:14.457060: Yayy! New best EMA pseudo Dice: 0.38350000977516174 
2025-03-10 21:52:15.788937:  
2025-03-10 21:52:15.789116: Epoch 15 
2025-03-10 21:52:15.789223: Current learning rate: 0.00864 
2025-03-10 21:56:25.946810: train_loss -0.5789 
2025-03-10 21:56:25.947083: val_loss -0.4917 
2025-03-10 21:56:25.947144: Pseudo dice [np.float32(0.5474)] 
2025-03-10 21:56:25.947226: Epoch time: 250.16 s 
2025-03-10 21:56:25.947282: Yayy! New best EMA pseudo Dice: 0.39989998936653137 
2025-03-10 21:56:27.314924:  
2025-03-10 21:56:27.315160: Epoch 16 
2025-03-10 21:56:27.315271: Current learning rate: 0.00855 
2025-03-10 22:00:37.558090: train_loss -0.5913 
2025-03-10 22:00:37.558362: val_loss -0.4891 
2025-03-10 22:00:37.558422: Pseudo dice [np.float32(0.5469)] 
2025-03-10 22:00:37.558499: Epoch time: 250.24 s 
2025-03-10 22:00:37.558555: Yayy! New best EMA pseudo Dice: 0.4146000146865845 
2025-03-10 22:00:38.926032:  
2025-03-10 22:00:38.926184: Epoch 17 
2025-03-10 22:00:38.926286: Current learning rate: 0.00846 
2025-03-10 22:04:49.155277: train_loss -0.5991 
2025-03-10 22:04:49.155540: val_loss -0.4766 
2025-03-10 22:04:49.155600: Pseudo dice [np.float32(0.5338)] 
2025-03-10 22:04:49.155691: Epoch time: 250.23 s 
2025-03-10 22:04:49.155748: Yayy! New best EMA pseudo Dice: 0.42649999260902405 
2025-03-10 22:04:50.527263:  
2025-03-10 22:04:50.527432: Epoch 18 
2025-03-10 22:04:50.527538: Current learning rate: 0.00836 
2025-03-10 22:09:00.615333: train_loss -0.6093 
2025-03-10 22:09:00.615615: val_loss -0.4822 
2025-03-10 22:09:00.615678: Pseudo dice [np.float32(0.5341)] 
2025-03-10 22:09:00.615762: Epoch time: 250.09 s 
2025-03-10 22:09:00.615820: Yayy! New best EMA pseudo Dice: 0.43720000982284546 
2025-03-10 22:09:02.014211:  
2025-03-10 22:09:02.014387: Epoch 19 
2025-03-10 22:09:02.014501: Current learning rate: 0.00827 
2025-03-10 22:13:12.063047: train_loss -0.6027 
2025-03-10 22:13:12.063298: val_loss -0.5027 
2025-03-10 22:13:12.063357: Pseudo dice [np.float32(0.5535)] 
2025-03-10 22:13:12.063441: Epoch time: 250.05 s 
2025-03-10 22:13:12.063498: Yayy! New best EMA pseudo Dice: 0.4489000141620636 
2025-03-10 22:13:13.683520:  
2025-03-10 22:13:13.683688: Epoch 20 
2025-03-10 22:13:13.683795: Current learning rate: 0.00818 
2025-03-10 22:17:23.753785: train_loss -0.6215 
2025-03-10 22:17:23.754026: val_loss -0.5093 
2025-03-10 22:17:23.754158: Pseudo dice [np.float32(0.5609)] 
2025-03-10 22:17:23.754232: Epoch time: 250.07 s 
2025-03-10 22:17:23.754287: Yayy! New best EMA pseudo Dice: 0.460099995136261 
2025-03-10 22:17:25.118429:  
2025-03-10 22:17:25.118685: Epoch 21 
2025-03-10 22:17:25.118794: Current learning rate: 0.00809 
2025-03-10 22:21:35.121959: train_loss -0.6254 
2025-03-10 22:21:35.122236: val_loss -0.5079 
2025-03-10 22:21:35.122296: Pseudo dice [np.float32(0.5613)] 
2025-03-10 22:21:35.122372: Epoch time: 250.0 s 
2025-03-10 22:21:35.122431: Yayy! New best EMA pseudo Dice: 0.4702000021934509 
2025-03-10 22:21:36.475340:  
2025-03-10 22:21:36.475522: Epoch 22 
2025-03-10 22:21:36.475629: Current learning rate: 0.008 
2025-03-10 22:25:46.485744: train_loss -0.6377 
2025-03-10 22:25:46.486009: val_loss -0.4934 
2025-03-10 22:25:46.486073: Pseudo dice [np.float32(0.5495)] 
2025-03-10 22:25:46.486151: Epoch time: 250.01 s 
2025-03-10 22:25:46.486219: Yayy! New best EMA pseudo Dice: 0.4781000018119812 
2025-03-10 22:25:47.824804:  
2025-03-10 22:25:47.824966: Epoch 23 
2025-03-10 22:25:47.825082: Current learning rate: 0.0079 
2025-03-10 22:29:57.937962: train_loss -0.6371 
2025-03-10 22:29:57.938259: val_loss -0.513 
2025-03-10 22:29:57.938320: Pseudo dice [np.float32(0.5626)] 
2025-03-10 22:29:57.938398: Epoch time: 250.11 s 
2025-03-10 22:29:57.938453: Yayy! New best EMA pseudo Dice: 0.48660001158714294 
2025-03-10 22:29:59.275358:  
2025-03-10 22:29:59.275528: Epoch 24 
2025-03-10 22:29:59.275632: Current learning rate: 0.00781 
2025-03-10 22:34:09.412541: train_loss -0.6482 
2025-03-10 22:34:09.412817: val_loss -0.4914 
2025-03-10 22:34:09.412879: Pseudo dice [np.float32(0.5406)] 
2025-03-10 22:34:09.412980: Epoch time: 250.14 s 
2025-03-10 22:34:09.413061: Yayy! New best EMA pseudo Dice: 0.492000013589859 
2025-03-10 22:34:10.850994:  
2025-03-10 22:34:10.851174: Epoch 25 
2025-03-10 22:34:10.851286: Current learning rate: 0.00772 
2025-03-10 22:38:20.921754: train_loss -0.6554 
2025-03-10 22:38:20.922016: val_loss -0.5137 
2025-03-10 22:38:20.922074: Pseudo dice [np.float32(0.5657)] 
2025-03-10 22:38:20.922154: Epoch time: 250.07 s 
2025-03-10 22:38:20.922212: Yayy! New best EMA pseudo Dice: 0.4993000030517578 
2025-03-10 22:38:22.252901:  
2025-03-10 22:38:22.253078: Epoch 26 
2025-03-10 22:38:22.253182: Current learning rate: 0.00763 
2025-03-10 22:42:32.310826: train_loss -0.6567 
2025-03-10 22:42:32.311095: val_loss -0.5169 
2025-03-10 22:42:32.311152: Pseudo dice [np.float32(0.5663)] 
2025-03-10 22:42:32.311232: Epoch time: 250.06 s 
2025-03-10 22:42:32.311291: Yayy! New best EMA pseudo Dice: 0.5059999823570251 
2025-03-10 22:42:33.648162:  
2025-03-10 22:42:33.648316: Epoch 27 
2025-03-10 22:42:33.648417: Current learning rate: 0.00753 
2025-03-10 22:46:43.755043: train_loss -0.652 
2025-03-10 22:46:43.755301: val_loss -0.4934 
2025-03-10 22:46:43.755367: Pseudo dice [np.float32(0.5455)] 
2025-03-10 22:46:43.755446: Epoch time: 250.11 s 
2025-03-10 22:46:43.755570: Yayy! New best EMA pseudo Dice: 0.5099999904632568 
2025-03-10 22:46:45.374158:  
2025-03-10 22:46:45.374313: Epoch 28 
2025-03-10 22:46:45.374422: Current learning rate: 0.00744 
2025-03-10 22:50:55.450569: train_loss -0.6553 
2025-03-10 22:50:55.450834: val_loss -0.5327 
2025-03-10 22:50:55.450896: Pseudo dice [np.float32(0.5851)] 
2025-03-10 22:50:55.450989: Epoch time: 250.08 s 
2025-03-10 22:50:55.451060: Yayy! New best EMA pseudo Dice: 0.5174999833106995 
2025-03-10 22:50:56.795956:  
2025-03-10 22:50:56.796121: Epoch 29 
2025-03-10 22:50:56.796228: Current learning rate: 0.00735 
2025-03-10 22:55:06.838790: train_loss -0.6708 
2025-03-10 22:55:06.839117: val_loss -0.496 
2025-03-10 22:55:06.839182: Pseudo dice [np.float32(0.5439)] 
2025-03-10 22:55:06.839274: Epoch time: 250.04 s 
2025-03-10 22:55:06.839333: Yayy! New best EMA pseudo Dice: 0.5200999975204468 
2025-03-10 22:55:08.193503:  
2025-03-10 22:55:08.193691: Epoch 30 
2025-03-10 22:55:08.193789: Current learning rate: 0.00725 
2025-03-10 22:59:18.273386: train_loss -0.6722 
2025-03-10 22:59:18.273661: val_loss -0.5102 
2025-03-10 22:59:18.273719: Pseudo dice [np.float32(0.559)] 
2025-03-10 22:59:18.273800: Epoch time: 250.08 s 
2025-03-10 22:59:18.273858: Yayy! New best EMA pseudo Dice: 0.5239999890327454 
2025-03-10 22:59:19.631661:  
2025-03-10 22:59:19.631826: Epoch 31 
2025-03-10 22:59:19.631934: Current learning rate: 0.00716 
2025-03-10 23:03:29.700061: train_loss -0.6739 
2025-03-10 23:03:29.700327: val_loss -0.508 
2025-03-10 23:03:29.700385: Pseudo dice [np.float32(0.5563)] 
2025-03-10 23:03:29.700462: Epoch time: 250.07 s 
2025-03-10 23:03:29.700519: Yayy! New best EMA pseudo Dice: 0.5273000001907349 
2025-03-10 23:03:31.089864:  
2025-03-10 23:03:31.090036: Epoch 32 
2025-03-10 23:03:31.090142: Current learning rate: 0.00707 
2025-03-10 23:07:41.217137: train_loss -0.6749 
2025-03-10 23:07:41.217394: val_loss -0.5038 
2025-03-10 23:07:41.217452: Pseudo dice [np.float32(0.5582)] 
2025-03-10 23:07:41.217540: Epoch time: 250.13 s 
2025-03-10 23:07:41.217598: Yayy! New best EMA pseudo Dice: 0.5303999781608582 
2025-03-10 23:07:42.567143:  
2025-03-10 23:07:42.567310: Epoch 33 
2025-03-10 23:07:42.567415: Current learning rate: 0.00697 
2025-03-10 23:11:52.645130: train_loss -0.687 
2025-03-10 23:11:52.645406: val_loss -0.512 
2025-03-10 23:11:52.645470: Pseudo dice [np.float32(0.5632)] 
2025-03-10 23:11:52.645543: Epoch time: 250.08 s 
2025-03-10 23:11:52.645603: Yayy! New best EMA pseudo Dice: 0.5335999727249146 
2025-03-10 23:11:53.999933:  
2025-03-10 23:11:54.000097: Epoch 34 
2025-03-10 23:11:54.000206: Current learning rate: 0.00688 
2025-03-10 23:16:04.225317: train_loss -0.6811 
2025-03-10 23:16:04.225586: val_loss -0.5413 
2025-03-10 23:16:04.225645: Pseudo dice [np.float32(0.5925)] 
2025-03-10 23:16:04.225728: Epoch time: 250.23 s 
2025-03-10 23:16:04.225788: Yayy! New best EMA pseudo Dice: 0.5394999980926514 
2025-03-10 23:16:05.603268:  
2025-03-10 23:16:05.603436: Epoch 35 
2025-03-10 23:16:05.603574: Current learning rate: 0.00679 
2025-03-10 23:20:15.869610: train_loss -0.6959 
2025-03-10 23:20:15.869908: val_loss -0.5264 
2025-03-10 23:20:15.869968: Pseudo dice [np.float32(0.5731)] 
2025-03-10 23:20:15.870052: Epoch time: 250.27 s 
2025-03-10 23:20:15.870114: Yayy! New best EMA pseudo Dice: 0.542900025844574 
2025-03-10 23:20:17.703846:  
2025-03-10 23:20:17.704147: Epoch 36 
2025-03-10 23:20:17.704292: Current learning rate: 0.00669 
2025-03-10 23:24:28.034393: train_loss -0.6827 
2025-03-10 23:24:28.034974: val_loss -0.5054 
2025-03-10 23:24:28.035038: Pseudo dice [np.float32(0.5542)] 
2025-03-10 23:24:28.035169: Epoch time: 250.33 s 
2025-03-10 23:24:28.035238: Yayy! New best EMA pseudo Dice: 0.5440000295639038 
2025-03-10 23:24:29.434617:  
2025-03-10 23:24:29.434824: Epoch 37 
2025-03-10 23:24:29.434952: Current learning rate: 0.0066 
2025-03-10 23:28:39.641166: train_loss -0.6924 
2025-03-10 23:28:39.641467: val_loss -0.5148 
2025-03-10 23:28:39.641524: Pseudo dice [np.float32(0.563)] 
2025-03-10 23:28:39.641605: Epoch time: 250.21 s 
2025-03-10 23:28:39.641662: Yayy! New best EMA pseudo Dice: 0.5458999872207642 
2025-03-10 23:28:40.989616:  
2025-03-10 23:28:40.989866: Epoch 38 
2025-03-10 23:28:40.989995: Current learning rate: 0.0065 
2025-03-10 23:32:51.221514: train_loss -0.698 
2025-03-10 23:32:51.221815: val_loss -0.5245 
2025-03-10 23:32:51.221874: Pseudo dice [np.float32(0.5787)] 
2025-03-10 23:32:51.221958: Epoch time: 250.23 s 
2025-03-10 23:32:51.222020: Yayy! New best EMA pseudo Dice: 0.5491999983787537 
2025-03-10 23:32:52.574525:  
2025-03-10 23:32:52.574705: Epoch 39 
2025-03-10 23:32:52.574826: Current learning rate: 0.00641 
2025-03-10 23:37:02.818655: train_loss -0.7046 
2025-03-10 23:37:02.818956: val_loss -0.5228 
2025-03-10 23:37:02.819015: Pseudo dice [np.float32(0.5756)] 
2025-03-10 23:37:02.819097: Epoch time: 250.25 s 
2025-03-10 23:37:02.819156: Yayy! New best EMA pseudo Dice: 0.551800012588501 
2025-03-10 23:37:04.191460:  
2025-03-10 23:37:04.191642: Epoch 40 
2025-03-10 23:37:04.191774: Current learning rate: 0.00631 
2025-03-10 23:41:14.409038: train_loss -0.7056 
2025-03-10 23:41:14.409313: val_loss -0.517 
2025-03-10 23:41:14.409372: Pseudo dice [np.float32(0.5685)] 
2025-03-10 23:41:14.409460: Epoch time: 250.22 s 
2025-03-10 23:41:14.409519: Yayy! New best EMA pseudo Dice: 0.5534999966621399 
2025-03-10 23:41:15.793999:  
2025-03-10 23:41:15.794252: Epoch 41 
2025-03-10 23:41:15.794383: Current learning rate: 0.00622 
2025-03-10 23:45:25.831716: train_loss -0.699 
2025-03-10 23:45:25.832020: val_loss -0.5242 
2025-03-10 23:45:25.832078: Pseudo dice [np.float32(0.5711)] 
2025-03-10 23:45:25.832165: Epoch time: 250.04 s 
2025-03-10 23:45:25.832225: Yayy! New best EMA pseudo Dice: 0.5552999973297119 
2025-03-10 23:45:27.172293:  
2025-03-10 23:45:27.172477: Epoch 42 
2025-03-10 23:45:27.172610: Current learning rate: 0.00612 
2025-03-10 23:49:37.260943: train_loss -0.7074 
2025-03-10 23:49:37.261233: val_loss -0.54 
2025-03-10 23:49:37.261291: Pseudo dice [np.float32(0.5882)] 
2025-03-10 23:49:37.261384: Epoch time: 250.09 s 
2025-03-10 23:49:37.261446: Yayy! New best EMA pseudo Dice: 0.5586000084877014 
2025-03-10 23:49:38.602694:  
2025-03-10 23:49:38.603051: Epoch 43 
2025-03-10 23:49:38.603243: Current learning rate: 0.00603 
2025-03-10 23:53:48.655334: train_loss -0.7165 
2025-03-10 23:53:48.655623: val_loss -0.5112 
2025-03-10 23:53:48.655683: Pseudo dice [np.float32(0.5588)] 
2025-03-10 23:53:48.655766: Epoch time: 250.05 s 
2025-03-10 23:53:48.655823: Yayy! New best EMA pseudo Dice: 0.5586000084877014 
2025-03-10 23:53:50.338306:  
2025-03-10 23:53:50.338727: Epoch 44 
2025-03-10 23:53:50.338905: Current learning rate: 0.00593 
2025-03-10 23:58:00.486498: train_loss -0.7138 
2025-03-10 23:58:00.486798: val_loss -0.5219 
2025-03-10 23:58:00.486860: Pseudo dice [np.float32(0.5685)] 
2025-03-10 23:58:00.486947: Epoch time: 250.15 s 
2025-03-10 23:58:00.487007: Yayy! New best EMA pseudo Dice: 0.5595999956130981 
2025-03-10 23:58:01.846262:  
2025-03-10 23:58:01.846809: Epoch 45 
2025-03-10 23:58:01.846951: Current learning rate: 0.00584 
2025-03-11 00:02:11.953675: train_loss -0.7055 
2025-03-11 00:02:11.953981: val_loss -0.5082 
2025-03-11 00:02:11.954041: Pseudo dice [np.float32(0.5605)] 
2025-03-11 00:02:11.954122: Epoch time: 250.11 s 
2025-03-11 00:02:11.954179: Yayy! New best EMA pseudo Dice: 0.5597000122070312 
2025-03-11 00:02:13.281355:  
2025-03-11 00:02:13.281583: Epoch 46 
2025-03-11 00:02:13.281719: Current learning rate: 0.00574 
2025-03-11 00:06:23.868296: train_loss -0.7165 
2025-03-11 00:06:23.868598: val_loss -0.5096 
2025-03-11 00:06:23.868660: Pseudo dice [np.float32(0.5618)] 
2025-03-11 00:06:23.868742: Epoch time: 250.59 s 
2025-03-11 00:06:23.868803: Yayy! New best EMA pseudo Dice: 0.5598999857902527 
2025-03-11 00:06:25.211770:  
2025-03-11 00:06:25.211968: Epoch 47 
2025-03-11 00:06:25.212088: Current learning rate: 0.00565 
2025-03-11 00:10:35.814743: train_loss -0.7222 
2025-03-11 00:10:35.815037: val_loss -0.5193 
2025-03-11 00:10:35.815096: Pseudo dice [np.float32(0.5703)] 
2025-03-11 00:10:35.815180: Epoch time: 250.6 s 
2025-03-11 00:10:35.815240: Yayy! New best EMA pseudo Dice: 0.5608999729156494 
2025-03-11 00:10:37.161889:  
2025-03-11 00:10:37.162069: Epoch 48 
2025-03-11 00:10:37.162196: Current learning rate: 0.00555 
2025-03-11 00:14:47.758336: train_loss -0.7312 
2025-03-11 00:14:47.758695: val_loss -0.5295 
2025-03-11 00:14:47.758757: Pseudo dice [np.float32(0.5761)] 
2025-03-11 00:14:47.758843: Epoch time: 250.6 s 
2025-03-11 00:14:47.758900: Yayy! New best EMA pseudo Dice: 0.5623999834060669 
2025-03-11 00:14:49.106460:  
2025-03-11 00:14:49.106657: Epoch 49 
2025-03-11 00:14:49.106786: Current learning rate: 0.00546 
2025-03-11 00:18:59.265602: train_loss -0.7186 
2025-03-11 00:18:59.265907: val_loss -0.5073 
2025-03-11 00:18:59.265972: Pseudo dice [np.float32(0.5582)] 
2025-03-11 00:18:59.266056: Epoch time: 250.16 s 
2025-03-11 00:19:00.583006:  
2025-03-11 00:19:00.583206: Epoch 50 
2025-03-11 00:19:00.583344: Current learning rate: 0.00536 
2025-03-11 00:23:10.678554: train_loss -0.7224 
2025-03-11 00:23:10.678837: val_loss -0.4925 
2025-03-11 00:23:10.678901: Pseudo dice [np.float32(0.5407)] 
2025-03-11 00:23:10.678982: Epoch time: 250.1 s 
2025-03-11 00:23:11.570736:  
2025-03-11 00:23:11.570924: Epoch 51 
2025-03-11 00:23:11.571051: Current learning rate: 0.00526 
2025-03-11 00:27:21.711548: train_loss -0.7343 
2025-03-11 00:27:21.711882: val_loss -0.5017 
2025-03-11 00:27:21.711946: Pseudo dice [np.float32(0.5508)] 
2025-03-11 00:27:21.712031: Epoch time: 250.14 s 
2025-03-11 00:27:22.851082:  
2025-03-11 00:27:22.851276: Epoch 52 
2025-03-11 00:27:22.851407: Current learning rate: 0.00517 
2025-03-11 00:31:33.065146: train_loss -0.7374 
2025-03-11 00:31:33.065443: val_loss -0.5082 
2025-03-11 00:31:33.065499: Pseudo dice [np.float32(0.5642)] 
2025-03-11 00:31:33.065589: Epoch time: 250.22 s 
2025-03-11 00:31:33.962252:  
2025-03-11 00:31:33.962463: Epoch 53 
2025-03-11 00:31:33.962592: Current learning rate: 0.00507 
2025-03-11 00:35:44.151677: train_loss -0.742 
2025-03-11 00:35:44.151970: val_loss -0.5566 
2025-03-11 00:35:44.152031: Pseudo dice [np.float32(0.6054)] 
2025-03-11 00:35:44.152113: Epoch time: 250.19 s 
2025-03-11 00:35:44.152172: Yayy! New best EMA pseudo Dice: 0.5641000270843506 
2025-03-11 00:35:45.491282:  
2025-03-11 00:35:45.491487: Epoch 54 
2025-03-11 00:35:45.491621: Current learning rate: 0.00497 
2025-03-11 00:39:55.687443: train_loss -0.7464 
2025-03-11 00:39:55.687736: val_loss -0.5366 
2025-03-11 00:39:55.687796: Pseudo dice [np.float32(0.5856)] 
2025-03-11 00:39:55.687880: Epoch time: 250.2 s 
2025-03-11 00:39:55.687938: Yayy! New best EMA pseudo Dice: 0.5662000179290771 
2025-03-11 00:39:57.066595:  
2025-03-11 00:39:57.066789: Epoch 55 
2025-03-11 00:39:57.066916: Current learning rate: 0.00487 
2025-03-11 00:44:07.248376: train_loss -0.7493 
2025-03-11 00:44:07.248680: val_loss -0.5379 
2025-03-11 00:44:07.248744: Pseudo dice [np.float32(0.5857)] 
2025-03-11 00:44:07.248831: Epoch time: 250.18 s 
2025-03-11 00:44:07.248889: Yayy! New best EMA pseudo Dice: 0.5681999921798706 
2025-03-11 00:44:08.593252:  
2025-03-11 00:44:08.593528: Epoch 56 
2025-03-11 00:44:08.593657: Current learning rate: 0.00478 
2025-03-11 00:48:18.843133: train_loss -0.7465 
2025-03-11 00:48:18.843393: val_loss -0.5242 
2025-03-11 00:48:18.843453: Pseudo dice [np.float32(0.5783)] 
2025-03-11 00:48:18.843535: Epoch time: 250.25 s 
2025-03-11 00:48:18.843592: Yayy! New best EMA pseudo Dice: 0.5691999793052673 
2025-03-11 00:48:20.186152:  
2025-03-11 00:48:20.186367: Epoch 57 
2025-03-11 00:48:20.186504: Current learning rate: 0.00468 
2025-03-11 00:52:30.444031: train_loss -0.7518 
2025-03-11 00:52:30.444300: val_loss -0.523 
2025-03-11 00:52:30.444361: Pseudo dice [np.float32(0.5712)] 
2025-03-11 00:52:30.444445: Epoch time: 250.26 s 
2025-03-11 00:52:30.444511: Yayy! New best EMA pseudo Dice: 0.5694000124931335 
2025-03-11 00:52:31.813575:  
2025-03-11 00:52:31.813785: Epoch 58 
2025-03-11 00:52:31.813919: Current learning rate: 0.00458 
2025-03-11 00:56:42.049696: train_loss -0.7574 
2025-03-11 00:56:42.050001: val_loss -0.5543 
2025-03-11 00:56:42.050062: Pseudo dice [np.float32(0.6031)] 
2025-03-11 00:56:42.050148: Epoch time: 250.24 s 
2025-03-11 00:56:42.050206: Yayy! New best EMA pseudo Dice: 0.5727999806404114 
2025-03-11 00:56:43.418810:  
2025-03-11 00:56:43.419014: Epoch 59 
2025-03-11 00:56:43.419150: Current learning rate: 0.00448 
2025-03-11 01:00:53.586953: train_loss -0.7544 
2025-03-11 01:00:53.587266: val_loss -0.5474 
2025-03-11 01:00:53.587326: Pseudo dice [np.float32(0.5998)] 
2025-03-11 01:00:53.587410: Epoch time: 250.17 s 
2025-03-11 01:00:53.587474: Yayy! New best EMA pseudo Dice: 0.5755000114440918 
2025-03-11 01:00:55.182999:  
2025-03-11 01:00:55.183205: Epoch 60 
2025-03-11 01:00:55.183340: Current learning rate: 0.00438 
2025-03-11 01:05:05.405386: train_loss -0.7613 
2025-03-11 01:05:05.405647: val_loss -0.5263 
2025-03-11 01:05:05.405705: Pseudo dice [np.float32(0.5788)] 
2025-03-11 01:05:05.405785: Epoch time: 250.22 s 
2025-03-11 01:05:05.405843: Yayy! New best EMA pseudo Dice: 0.5758000016212463 
2025-03-11 01:05:06.755207:  
2025-03-11 01:05:06.755397: Epoch 61 
2025-03-11 01:05:06.755538: Current learning rate: 0.00429 
2025-03-11 01:09:17.054597: train_loss -0.7645 
2025-03-11 01:09:17.054862: val_loss -0.5393 
2025-03-11 01:09:17.054924: Pseudo dice [np.float32(0.589)] 
2025-03-11 01:09:17.055007: Epoch time: 250.3 s 
2025-03-11 01:09:17.055071: Yayy! New best EMA pseudo Dice: 0.5770999789237976 
2025-03-11 01:09:18.400141:  
2025-03-11 01:09:18.400528: Epoch 62 
2025-03-11 01:09:18.400707: Current learning rate: 0.00419 
2025-03-11 01:13:28.511136: train_loss -0.7674 
2025-03-11 01:13:28.511510: val_loss -0.5414 
2025-03-11 01:13:28.511589: Pseudo dice [np.float32(0.5904)] 
2025-03-11 01:13:28.511677: Epoch time: 250.11 s 
2025-03-11 01:13:28.511735: Yayy! New best EMA pseudo Dice: 0.578499972820282 
2025-03-11 01:13:29.867684:  
2025-03-11 01:13:29.867891: Epoch 63 
2025-03-11 01:13:29.868033: Current learning rate: 0.00409 
2025-03-11 01:17:40.037981: train_loss -0.7699 
2025-03-11 01:17:40.038272: val_loss -0.5581 
2025-03-11 01:17:40.038333: Pseudo dice [np.float32(0.6094)] 
2025-03-11 01:17:40.038416: Epoch time: 250.17 s 
2025-03-11 01:17:40.038470: Yayy! New best EMA pseudo Dice: 0.58160001039505 
2025-03-11 01:17:41.380341:  
2025-03-11 01:17:41.380742: Epoch 64 
2025-03-11 01:17:41.380879: Current learning rate: 0.00399 
2025-03-11 01:21:51.551841: train_loss -0.7663 
2025-03-11 01:21:51.552145: val_loss -0.5263 
2025-03-11 01:21:51.552204: Pseudo dice [np.float32(0.5788)] 
2025-03-11 01:21:51.552291: Epoch time: 250.17 s 
2025-03-11 01:21:52.452430:  
2025-03-11 01:21:52.452636: Epoch 65 
2025-03-11 01:21:52.452776: Current learning rate: 0.00389 
2025-03-11 01:26:02.624295: train_loss -0.7698 
2025-03-11 01:26:02.624550: val_loss -0.5295 
2025-03-11 01:26:02.624619: Pseudo dice [np.float32(0.5794)] 
2025-03-11 01:26:02.624701: Epoch time: 250.17 s 
2025-03-11 01:26:03.523646:  
2025-03-11 01:26:03.523839: Epoch 66 
2025-03-11 01:26:03.523968: Current learning rate: 0.00379 
2025-03-11 01:30:13.683952: train_loss -0.771 
2025-03-11 01:30:13.684247: val_loss -0.5386 
2025-03-11 01:30:13.684305: Pseudo dice [np.float32(0.5861)] 
2025-03-11 01:30:13.684389: Epoch time: 250.16 s 
2025-03-11 01:30:13.684449: Yayy! New best EMA pseudo Dice: 0.58160001039505 
2025-03-11 01:30:15.061535:  
2025-03-11 01:30:15.061749: Epoch 67 
2025-03-11 01:30:15.061888: Current learning rate: 0.00369 
2025-03-11 01:34:25.333478: train_loss -0.7735 
2025-03-11 01:34:25.333818: val_loss -0.5246 
2025-03-11 01:34:25.334073: Pseudo dice [np.float32(0.5827)] 
2025-03-11 01:34:25.334152: Epoch time: 250.27 s 
2025-03-11 01:34:25.334216: Yayy! New best EMA pseudo Dice: 0.5817000269889832 
2025-03-11 01:34:26.699463:  
2025-03-11 01:34:26.699754: Epoch 68 
2025-03-11 01:34:26.699894: Current learning rate: 0.00359 
2025-03-11 01:38:36.997305: train_loss -0.7799 
2025-03-11 01:38:36.997572: val_loss -0.5317 
2025-03-11 01:38:36.997631: Pseudo dice [np.float32(0.5847)] 
2025-03-11 01:38:36.997710: Epoch time: 250.3 s 
2025-03-11 01:38:36.997770: Yayy! New best EMA pseudo Dice: 0.5820000171661377 
2025-03-11 01:38:38.346695:  
2025-03-11 01:38:38.346910: Epoch 69 
2025-03-11 01:38:38.347046: Current learning rate: 0.00349 
2025-03-11 01:42:48.478127: train_loss -0.7761 
2025-03-11 01:42:48.478417: val_loss -0.5212 
2025-03-11 01:42:48.478481: Pseudo dice [np.float32(0.5747)] 
2025-03-11 01:42:48.478563: Epoch time: 250.13 s 
2025-03-11 01:42:49.384403:  
2025-03-11 01:42:49.384592: Epoch 70 
2025-03-11 01:42:49.384717: Current learning rate: 0.00338 
2025-03-11 01:47:00.033036: train_loss -0.7774 
2025-03-11 01:47:00.033334: val_loss -0.5485 
2025-03-11 01:47:00.033391: Pseudo dice [np.float32(0.5946)] 
2025-03-11 01:47:00.033474: Epoch time: 250.65 s 
2025-03-11 01:47:00.033533: Yayy! New best EMA pseudo Dice: 0.5825999975204468 
2025-03-11 01:47:01.410247:  
2025-03-11 01:47:01.410444: Epoch 71 
2025-03-11 01:47:01.410579: Current learning rate: 0.00328 
2025-03-11 01:51:11.596993: train_loss -0.7742 
2025-03-11 01:51:11.597358: val_loss -0.5528 
2025-03-11 01:51:11.597421: Pseudo dice [np.float32(0.5999)] 
2025-03-11 01:51:11.597501: Epoch time: 250.19 s 
2025-03-11 01:51:11.597554: Yayy! New best EMA pseudo Dice: 0.5842999815940857 
2025-03-11 01:51:12.967679:  
2025-03-11 01:51:12.967884: Epoch 72 
2025-03-11 01:51:12.968022: Current learning rate: 0.00318 
2025-03-11 01:55:23.156181: train_loss -0.7833 
2025-03-11 01:55:23.156479: val_loss -0.5412 
2025-03-11 01:55:23.156538: Pseudo dice [np.float32(0.5871)] 
2025-03-11 01:55:23.156620: Epoch time: 250.19 s 
2025-03-11 01:55:23.156678: Yayy! New best EMA pseudo Dice: 0.5845999717712402 
2025-03-11 01:55:24.511865:  
2025-03-11 01:55:24.512123: Epoch 73 
2025-03-11 01:55:24.512258: Current learning rate: 0.00308 
2025-03-11 01:59:34.752626: train_loss -0.7876 
2025-03-11 01:59:34.752890: val_loss -0.504 
2025-03-11 01:59:34.752948: Pseudo dice [np.float32(0.5557)] 
2025-03-11 01:59:34.753054: Epoch time: 250.24 s 
2025-03-11 01:59:35.661298:  
2025-03-11 01:59:35.661487: Epoch 74 
2025-03-11 01:59:35.661626: Current learning rate: 0.00297 
2025-03-11 02:03:45.895361: train_loss -0.7884 
2025-03-11 02:03:45.895611: val_loss -0.526 
2025-03-11 02:03:45.895671: Pseudo dice [np.float32(0.5783)] 
2025-03-11 02:03:45.895748: Epoch time: 250.24 s 
2025-03-11 02:03:46.801371:  
2025-03-11 02:03:46.801663: Epoch 75 
2025-03-11 02:03:46.801801: Current learning rate: 0.00287 
2025-03-11 02:07:56.966992: train_loss -0.7964 
2025-03-11 02:07:56.967278: val_loss -0.5054 
2025-03-11 02:07:56.967339: Pseudo dice [np.float32(0.5612)] 
2025-03-11 02:07:56.967420: Epoch time: 250.17 s 
2025-03-11 02:07:57.872295:  
2025-03-11 02:07:57.872559: Epoch 76 
2025-03-11 02:07:57.872690: Current learning rate: 0.00277 
2025-03-11 02:12:08.018584: train_loss -0.793 
2025-03-11 02:12:08.018879: val_loss -0.5264 
2025-03-11 02:12:08.018938: Pseudo dice [np.float32(0.5759)] 
2025-03-11 02:12:08.019023: Epoch time: 250.15 s 
2025-03-11 02:12:09.170769:  
2025-03-11 02:12:09.170984: Epoch 77 
2025-03-11 02:12:09.171118: Current learning rate: 0.00266 
2025-03-11 02:16:19.316500: train_loss -0.7961 
2025-03-11 02:16:19.316811: val_loss -0.5386 
2025-03-11 02:16:19.316870: Pseudo dice [np.float32(0.5904)] 
2025-03-11 02:16:19.316952: Epoch time: 250.15 s 
2025-03-11 02:16:20.227433:  
2025-03-11 02:16:20.227644: Epoch 78 
2025-03-11 02:16:20.227777: Current learning rate: 0.00256 
2025-03-11 02:20:30.400357: train_loss -0.798 
2025-03-11 02:20:30.400593: val_loss -0.54 
2025-03-11 02:20:30.400650: Pseudo dice [np.float32(0.5886)] 
2025-03-11 02:20:30.400723: Epoch time: 250.17 s 
2025-03-11 02:20:31.313062:  
2025-03-11 02:20:31.313303: Epoch 79 
2025-03-11 02:20:31.313445: Current learning rate: 0.00245 
2025-03-11 02:24:41.939012: train_loss -0.8034 
2025-03-11 02:24:41.939317: val_loss -0.5339 
2025-03-11 02:24:41.939376: Pseudo dice [np.float32(0.5815)] 
2025-03-11 02:24:41.939458: Epoch time: 250.63 s 
2025-03-11 02:24:42.858073:  
2025-03-11 02:24:42.858311: Epoch 80 
2025-03-11 02:24:42.858452: Current learning rate: 0.00235 
2025-03-11 02:28:53.043741: train_loss -0.7957 
2025-03-11 02:28:53.043965: val_loss -0.5594 
2025-03-11 02:28:53.044023: Pseudo dice [np.float32(0.608)] 
2025-03-11 02:28:53.044099: Epoch time: 250.19 s 
2025-03-11 02:28:53.982115:  
2025-03-11 02:28:53.982293: Epoch 81 
2025-03-11 02:28:53.982423: Current learning rate: 0.00224 
2025-03-11 02:33:04.115390: train_loss -0.8028 
2025-03-11 02:33:04.115689: val_loss -0.5564 
2025-03-11 02:33:04.115746: Pseudo dice [np.float32(0.6056)] 
2025-03-11 02:33:04.115828: Epoch time: 250.13 s 
2025-03-11 02:33:04.115885: Yayy! New best EMA pseudo Dice: 0.5859000086784363 
2025-03-11 02:33:05.491824:  
2025-03-11 02:33:05.492044: Epoch 82 
2025-03-11 02:33:05.492186: Current learning rate: 0.00214 
2025-03-11 02:37:15.657538: train_loss -0.8068 
2025-03-11 02:37:15.657810: val_loss -0.549 
2025-03-11 02:37:15.657867: Pseudo dice [np.float32(0.6019)] 
2025-03-11 02:37:15.657949: Epoch time: 250.17 s 
2025-03-11 02:37:15.658007: Yayy! New best EMA pseudo Dice: 0.5874999761581421 
2025-03-11 02:37:17.005789:  
2025-03-11 02:37:17.006071: Epoch 83 
2025-03-11 02:37:17.006215: Current learning rate: 0.00203 
2025-03-11 02:41:27.223119: train_loss -0.806 
2025-03-11 02:41:27.223393: val_loss -0.5598 
2025-03-11 02:41:27.223450: Pseudo dice [np.float32(0.6051)] 
2025-03-11 02:41:27.223523: Epoch time: 250.22 s 
2025-03-11 02:41:27.223579: Yayy! New best EMA pseudo Dice: 0.5892999768257141 
2025-03-11 02:41:28.551049:  
2025-03-11 02:41:28.551222: Epoch 84 
2025-03-11 02:41:28.551418: Current learning rate: 0.00192 
2025-03-11 02:45:38.722049: train_loss -0.8088 
2025-03-11 02:45:38.722332: val_loss -0.5375 
2025-03-11 02:45:38.722390: Pseudo dice [np.float32(0.5879)] 
2025-03-11 02:45:38.722470: Epoch time: 250.17 s 
2025-03-11 02:45:39.856001:  
2025-03-11 02:45:39.856204: Epoch 85 
2025-03-11 02:45:39.856338: Current learning rate: 0.00181 
2025-03-11 02:49:50.051698: train_loss -0.8117 
2025-03-11 02:49:50.051966: val_loss -0.5342 
2025-03-11 02:49:50.052027: Pseudo dice [np.float32(0.5853)] 
2025-03-11 02:49:50.052106: Epoch time: 250.2 s 
2025-03-11 02:49:50.922844:  
2025-03-11 02:49:50.923052: Epoch 86 
2025-03-11 02:49:50.923186: Current learning rate: 0.0017 
2025-03-11 02:54:01.197389: train_loss -0.8098 
2025-03-11 02:54:01.197671: val_loss -0.5494 
2025-03-11 02:54:01.197729: Pseudo dice [np.float32(0.5979)] 
2025-03-11 02:54:01.197813: Epoch time: 250.28 s 
2025-03-11 02:54:01.197872: Yayy! New best EMA pseudo Dice: 0.5896999835968018 
2025-03-11 02:54:02.539899:  
2025-03-11 02:54:02.540087: Epoch 87 
2025-03-11 02:54:02.540220: Current learning rate: 0.00159 
2025-03-11 02:58:12.793028: train_loss -0.8118 
2025-03-11 02:58:12.793310: val_loss -0.5278 
2025-03-11 02:58:12.793369: Pseudo dice [np.float32(0.5737)] 
2025-03-11 02:58:12.793449: Epoch time: 250.25 s 
2025-03-11 02:58:13.673179:  
2025-03-11 02:58:13.673379: Epoch 88 
2025-03-11 02:58:13.673516: Current learning rate: 0.00148 
2025-03-11 03:02:23.901509: train_loss -0.8146 
2025-03-11 03:02:23.901791: val_loss -0.5475 
2025-03-11 03:02:23.901851: Pseudo dice [np.float32(0.5991)] 
2025-03-11 03:02:23.901931: Epoch time: 250.23 s 
2025-03-11 03:02:24.781783:  
2025-03-11 03:02:24.782049: Epoch 89 
2025-03-11 03:02:24.782188: Current learning rate: 0.00137 
2025-03-11 03:06:34.958642: train_loss -0.8189 
2025-03-11 03:06:34.958942: val_loss -0.5407 
2025-03-11 03:06:34.959000: Pseudo dice [np.float32(0.5894)] 
2025-03-11 03:06:34.959082: Epoch time: 250.18 s 
2025-03-11 03:06:35.842185:  
2025-03-11 03:06:35.842375: Epoch 90 
2025-03-11 03:06:35.842500: Current learning rate: 0.00126 
2025-03-11 03:10:46.072018: train_loss -0.8243 
2025-03-11 03:10:46.072289: val_loss -0.5365 
2025-03-11 03:10:46.072346: Pseudo dice [np.float32(0.5888)] 
2025-03-11 03:10:46.072429: Epoch time: 250.23 s 
2025-03-11 03:10:46.955770:  
2025-03-11 03:10:46.955973: Epoch 91 
2025-03-11 03:10:46.956108: Current learning rate: 0.00115 
2025-03-11 03:14:57.138038: train_loss -0.8183 
2025-03-11 03:14:57.138322: val_loss -0.5251 
2025-03-11 03:14:57.138383: Pseudo dice [np.float32(0.5748)] 
2025-03-11 03:14:57.138461: Epoch time: 250.18 s 
2025-03-11 03:14:58.018910:  
2025-03-11 03:14:58.019112: Epoch 92 
2025-03-11 03:14:58.019246: Current learning rate: 0.00103 
2025-03-11 03:19:08.219468: train_loss -0.8227 
2025-03-11 03:19:08.219772: val_loss -0.5424 
2025-03-11 03:19:08.219831: Pseudo dice [np.float32(0.5928)] 
2025-03-11 03:19:08.219912: Epoch time: 250.2 s 
2025-03-11 03:19:09.123619:  
2025-03-11 03:19:09.123884: Epoch 93 
2025-03-11 03:19:09.124041: Current learning rate: 0.00091 
2025-03-11 03:23:19.359753: train_loss -0.8271 
2025-03-11 03:23:19.360040: val_loss -0.5429 
2025-03-11 03:23:19.360101: Pseudo dice [np.float32(0.5944)] 
2025-03-11 03:23:19.360184: Epoch time: 250.24 s 
2025-03-11 03:23:20.485710:  
2025-03-11 03:23:20.485897: Epoch 94 
2025-03-11 03:23:20.486030: Current learning rate: 0.00079 
2025-03-11 03:27:30.815882: train_loss -0.8297 
2025-03-11 03:27:30.816123: val_loss -0.5566 
2025-03-11 03:27:30.816180: Pseudo dice [np.float32(0.6057)] 
2025-03-11 03:27:30.816257: Epoch time: 250.33 s 
2025-03-11 03:27:30.816316: Yayy! New best EMA pseudo Dice: 0.590499997138977 
2025-03-11 03:27:32.150154:  
2025-03-11 03:27:32.150352: Epoch 95 
2025-03-11 03:27:32.150483: Current learning rate: 0.00067 
2025-03-11 03:31:42.424888: train_loss -0.8288 
2025-03-11 03:31:42.425184: val_loss -0.5378 
2025-03-11 03:31:42.425246: Pseudo dice [np.float32(0.5876)] 
2025-03-11 03:31:42.425331: Epoch time: 250.28 s 
2025-03-11 03:31:43.306043:  
2025-03-11 03:31:43.306269: Epoch 96 
2025-03-11 03:31:43.306405: Current learning rate: 0.00055 
2025-03-11 03:35:53.604625: train_loss -0.8327 
2025-03-11 03:35:53.604915: val_loss -0.558 
2025-03-11 03:35:53.604978: Pseudo dice [np.float32(0.6112)] 
2025-03-11 03:35:53.605069: Epoch time: 250.3 s 
2025-03-11 03:35:53.605127: Yayy! New best EMA pseudo Dice: 0.5922999978065491 
2025-03-11 03:35:54.942411:  
2025-03-11 03:35:54.942601: Epoch 97 
2025-03-11 03:35:54.942732: Current learning rate: 0.00043 
2025-03-11 03:40:05.110370: train_loss -0.8325 
2025-03-11 03:40:05.110659: val_loss -0.5516 
2025-03-11 03:40:05.110721: Pseudo dice [np.float32(0.6062)] 
2025-03-11 03:40:05.110802: Epoch time: 250.17 s 
2025-03-11 03:40:05.110858: Yayy! New best EMA pseudo Dice: 0.5936999917030334 
2025-03-11 03:40:06.485982:  
2025-03-11 03:40:06.486287: Epoch 98 
2025-03-11 03:40:06.486427: Current learning rate: 0.0003 
2025-03-11 03:44:16.708099: train_loss -0.8304 
2025-03-11 03:44:16.708419: val_loss -0.5484 
2025-03-11 03:44:16.708478: Pseudo dice [np.float32(0.5973)] 
2025-03-11 03:44:16.708564: Epoch time: 250.22 s 
2025-03-11 03:44:16.708625: Yayy! New best EMA pseudo Dice: 0.5940999984741211 
2025-03-11 03:44:18.064368:  
2025-03-11 03:44:18.064561: Epoch 99 
2025-03-11 03:44:18.064697: Current learning rate: 0.00016 
2025-03-11 03:48:28.208322: train_loss -0.8306 
2025-03-11 03:48:28.208586: val_loss -0.5573 
2025-03-11 03:48:28.208649: Pseudo dice [np.float32(0.6035)] 
2025-03-11 03:48:28.208731: Epoch time: 250.15 s 
2025-03-11 03:48:28.208793: Yayy! New best EMA pseudo Dice: 0.5950000286102295 
2025-03-11 03:48:30.092432: Using splits from existing split file: ./nnNet_training/nnUNet_preprocessed/Dataset_Train_val/splits_final.json 
2025-03-11 03:48:30.092998: The split file contains 5 splits. 
2025-03-11 03:48:30.093060: Desired fold for training: 0 
2025-03-11 03:48:30.093102: This split has 800 training and 200 validation cases. 
2025-03-11 03:48:30.095120: predicting sten_0000 
2025-03-11 03:48:30.815593: predicting sten_0003 
2025-03-11 03:48:31.615340: predicting sten_0004 
2025-03-11 03:48:32.234543: predicting sten_0010 
2025-03-11 03:48:32.394153: predicting sten_0017 
2025-03-11 03:48:32.530859: predicting sten_0033 
2025-03-11 03:48:32.657170: predicting sten_0041 
2025-03-11 03:48:32.783342: predicting sten_0047 
2025-03-11 03:48:32.914658: predicting sten_0053 
2025-03-11 03:48:33.038985: predicting sten_0056 
2025-03-11 03:48:33.166204: predicting sten_0060 
2025-03-11 03:48:33.292413: predicting sten_0065 
2025-03-11 03:48:33.433272: predicting sten_0073 
2025-03-11 03:48:33.559707: predicting sten_0090 
2025-03-11 03:48:33.685994: predicting sten_0101 
2025-03-11 03:48:33.822072: predicting sten_0104 
2025-03-11 03:48:33.948621: predicting sten_0106 
2025-03-11 03:48:36.113437: predicting sten_0109 
2025-03-11 03:48:37.915546: predicting sten_0111 
2025-03-11 03:48:41.216430: predicting sten_0115 
2025-03-11 03:48:41.615300: predicting sten_0117 
2025-03-11 03:48:42.218773: predicting sten_0127 
2025-03-11 03:48:42.593957: predicting sten_0130 
2025-03-11 03:48:43.020543: predicting sten_0133 
2025-03-11 03:48:43.416688: predicting sten_0135 
2025-03-11 03:48:43.821491: predicting sten_0136 
2025-03-11 03:48:44.187849: predicting sten_0138 
2025-03-11 03:48:44.505938: predicting sten_0144 
2025-03-11 03:48:44.921342: predicting sten_0150 
2025-03-11 03:48:45.292163: predicting sten_0153 
2025-03-11 03:48:45.566244: predicting sten_0156 
2025-03-11 03:48:45.908573: predicting sten_0158 
2025-03-11 03:48:46.289330: predicting sten_0162 
2025-03-11 03:48:46.663772: predicting sten_0164 
2025-03-11 03:48:46.963497: predicting sten_0168 
2025-03-11 03:48:47.291028: predicting sten_0173 
2025-03-11 03:48:47.594070: predicting sten_0181 
2025-03-11 03:48:47.914807: predicting sten_0186 
2025-03-11 03:48:48.315026: predicting sten_0187 
2025-03-11 03:48:48.656489: predicting sten_0190 
2025-03-11 03:48:48.957121: predicting sten_0196 
2025-03-11 03:48:49.372344: predicting sten_0198 
2025-03-11 03:48:49.722999: predicting sten_0199 
2025-03-11 03:48:50.123653: predicting sten_0203 
2025-03-11 03:48:50.464544: predicting sten_0207 
2025-03-11 03:48:50.830620: predicting sten_0216 
2025-03-11 03:48:51.211697: predicting sten_0220 
2025-03-11 03:48:51.621730: predicting sten_0222 
2025-03-11 03:48:51.991915: predicting sten_0238 
2025-03-11 03:48:52.306213: predicting sten_0239 
2025-03-11 03:48:52.687666: predicting sten_0244 
2025-03-11 03:48:53.018917: predicting sten_0250 
2025-03-11 03:48:53.408000: predicting sten_0254 
2025-03-11 03:48:53.786594: predicting sten_0258 
2025-03-11 03:48:54.099252: predicting sten_0262 
2025-03-11 03:48:54.408969: predicting sten_0266 
2025-03-11 03:48:54.824100: predicting sten_0268 
2025-03-11 03:48:55.225872: predicting sten_0270 
2025-03-11 03:48:55.631181: predicting sten_0280 
2025-03-11 03:48:56.023094: predicting sten_0281 
2025-03-11 03:48:56.358458: predicting sten_0284 
2025-03-11 03:48:56.698834: predicting sten_0286 
2025-03-11 03:48:57.014832: predicting sten_0296 
2025-03-11 03:48:57.384866: predicting sten_0298 
2025-03-11 03:48:57.682675: predicting sten_0304 
2025-03-11 03:48:58.015056: predicting sten_0308 
2025-03-11 03:48:58.404479: predicting sten_0311 
2025-03-11 03:48:58.828583: predicting sten_0314 
2025-03-11 03:48:59.231084: predicting sten_0320 
2025-03-11 03:48:59.593475: predicting sten_0322 
2025-03-11 03:48:59.905959: predicting sten_0326 
2025-03-11 03:49:00.313740: predicting sten_0327 
2025-03-11 03:49:00.706432: predicting sten_0328 
2025-03-11 03:49:01.130886: predicting sten_0332 
2025-03-11 03:49:01.433716: predicting sten_0334 
2025-03-11 03:49:01.823347: predicting sten_0343 
2025-03-11 03:49:02.193861: predicting sten_0346 
2025-03-11 03:49:02.503699: predicting sten_0352 
2025-03-11 03:49:02.919258: predicting sten_0358 
2025-03-11 03:49:03.330803: predicting sten_0370 
2025-03-11 03:49:03.707262: predicting sten_0377 
2025-03-11 03:49:04.123175: predicting sten_0380 
2025-03-11 03:49:04.509483: predicting sten_0391 
2025-03-11 03:49:04.895250: predicting sten_0400 
2025-03-11 03:49:05.210917: predicting sten_0404 
2025-03-11 03:49:05.619969: predicting sten_0413 
2025-03-11 03:49:06.005800: predicting sten_0422 
2025-03-11 03:49:06.370747: predicting sten_0430 
2025-03-11 03:49:06.637016: predicting sten_0435 
2025-03-11 03:49:06.988034: predicting sten_0437 
2025-03-11 03:49:07.322742: predicting sten_0440 
2025-03-11 03:49:07.661115: predicting sten_0454 
2025-03-11 03:49:08.019972: predicting sten_0458 
2025-03-11 03:49:08.427963: predicting sten_0462 
2025-03-11 03:49:08.832466: predicting sten_0468 
2025-03-11 03:49:09.191087: predicting sten_0469 
2025-03-11 03:49:09.532804: predicting sten_0473 
2025-03-11 03:49:09.920422: predicting sten_0474 
2025-03-11 03:49:10.284055: predicting sten_0479 
2025-03-11 03:49:10.616218: predicting sten_0481 
2025-03-11 03:49:10.984287: predicting sten_0484 
2025-03-11 03:49:11.301682: predicting sten_0488 
2025-03-11 03:49:11.667315: predicting sten_0493 
2025-03-11 03:49:12.013553: predicting sten_0503 
2025-03-11 03:49:12.425497: predicting sten_0504 
2025-03-11 03:49:12.815594: predicting sten_0509 
2025-03-11 03:49:13.206252: predicting sten_0516 
2025-03-11 03:49:13.564726: predicting sten_0517 
2025-03-11 03:49:13.921182: predicting sten_0521 
2025-03-11 03:49:14.310094: predicting sten_0540 
2025-03-11 03:49:14.684618: predicting sten_0545 
2025-03-11 03:49:15.017324: predicting sten_0551 
2025-03-11 03:49:15.418783: predicting sten_0558 
2025-03-11 03:49:15.809328: predicting sten_0560 
2025-03-11 03:49:16.222777: predicting sten_0566 
2025-03-11 03:49:16.562832: predicting sten_0569 
2025-03-11 03:49:16.893549: predicting sten_0578 
2025-03-11 03:49:17.194456: predicting sten_0582 
2025-03-11 03:49:17.506309: predicting sten_0589 
2025-03-11 03:49:17.898696: predicting sten_0590 
2025-03-11 03:49:18.163783: predicting sten_0593 
2025-03-11 03:49:18.434290: predicting sten_0599 
2025-03-11 03:49:18.815289: predicting sten_0603 
2025-03-11 03:49:19.216540: predicting sten_0604 
2025-03-11 03:49:19.592624: predicting sten_0606 
2025-03-11 03:49:19.866332: predicting sten_0609 
2025-03-11 03:49:20.222511: predicting sten_0613 
2025-03-11 03:49:20.523194: predicting sten_0617 
2025-03-11 03:49:20.890126: predicting sten_0624 
2025-03-11 03:49:21.172903: predicting sten_0625 
2025-03-11 03:49:21.492151: predicting sten_0634 
2025-03-11 03:49:21.784667: predicting sten_0656 
2025-03-11 03:49:22.175714: predicting sten_0663 
2025-03-11 03:49:22.507412: predicting sten_0664 
2025-03-11 03:49:22.911254: predicting sten_0671 
2025-03-11 03:49:23.311095: predicting sten_0677 
2025-03-11 03:49:23.689696: predicting sten_0680 
2025-03-11 03:49:23.977935: predicting sten_0696 
2025-03-11 03:49:24.298790: predicting sten_0700 
2025-03-11 03:49:24.584530: predicting sten_0703 
2025-03-11 03:49:24.888608: predicting sten_0719 
2025-03-11 03:49:25.229200: predicting sten_0725 
2025-03-11 03:49:25.618971: predicting sten_0726 
2025-03-11 03:49:25.977002: predicting sten_0727 
2025-03-11 03:49:26.305028: predicting sten_0732 
2025-03-11 03:49:26.715704: predicting sten_0733 
2025-03-11 03:49:27.114313: predicting sten_0741 
2025-03-11 03:49:27.487142: predicting sten_0743 
2025-03-11 03:49:27.816240: predicting sten_0746 
2025-03-11 03:49:28.218284: predicting sten_0754 
2025-03-11 03:49:28.591651: predicting sten_0757 
2025-03-11 03:49:28.911406: predicting sten_0758 
2025-03-11 03:49:29.293341: predicting sten_0761 
2025-03-11 03:49:29.623354: predicting sten_0765 
2025-03-11 03:49:29.975279: predicting sten_0768 
2025-03-11 03:49:30.314024: predicting sten_0771 
2025-03-11 03:49:30.705742: predicting sten_0776 
2025-03-11 03:49:31.068118: predicting sten_0777 
2025-03-11 03:49:31.331872: predicting sten_0787 
2025-03-11 03:49:31.689870: predicting sten_0795 
2025-03-11 03:49:31.964817: predicting sten_0802 
2025-03-11 03:49:32.290688: predicting sten_0804 
2025-03-11 03:49:32.609036: predicting sten_0821 
2025-03-11 03:49:32.957680: predicting sten_0826 
2025-03-11 03:49:33.359128: predicting sten_0829 
2025-03-11 03:49:33.687312: predicting sten_0832 
2025-03-11 03:49:33.933244: predicting sten_0833 
2025-03-11 03:49:34.313509: predicting sten_0838 
2025-03-11 03:49:34.688880: predicting sten_0853 
2025-03-11 03:49:35.087540: predicting sten_0854 
2025-03-11 03:49:35.421270: predicting sten_0865 
2025-03-11 03:49:35.761614: predicting sten_0878 
2025-03-11 03:49:36.117021: predicting sten_0883 
2025-03-11 03:49:36.513221: predicting sten_0884 
2025-03-11 03:49:36.920616: predicting sten_0889 
2025-03-11 03:49:37.308936: predicting sten_0890 
2025-03-11 03:49:37.730042: predicting sten_0893 
2025-03-11 03:49:38.119311: predicting sten_0911 
2025-03-11 03:49:38.505458: predicting sten_0912 
2025-03-11 03:49:38.923337: predicting sten_0913 
2025-03-11 03:49:39.301425: predicting sten_0914 
2025-03-11 03:49:39.708821: predicting sten_0915 
2025-03-11 03:49:40.092888: predicting sten_0925 
2025-03-11 03:49:40.434220: predicting sten_0937 
2025-03-11 03:49:40.789302: predicting sten_0940 
2025-03-11 03:49:41.094065: predicting sten_0942 
2025-03-11 03:49:41.415548: predicting sten_0943 
2025-03-11 03:49:41.787858: predicting sten_0954 
2025-03-11 03:49:42.115164: predicting sten_0955 
2025-03-11 03:49:42.517272: predicting sten_0957 
2025-03-11 03:49:42.916355: predicting sten_0961 
2025-03-11 03:49:43.321136: predicting sten_0962 
2025-03-11 03:49:43.718012: predicting sten_0966 
2025-03-11 03:49:44.090142: predicting sten_0967 
2025-03-11 03:49:44.357085: predicting sten_0974 
2025-03-11 03:49:44.710100: predicting sten_0977 
2025-03-11 03:49:45.090105: predicting sten_0979 
2025-03-11 03:49:45.429378: predicting sten_0981 
2025-03-11 03:49:45.788903: predicting sten_0982 
2025-03-11 03:49:46.125529: predicting sten_0997 
2025-03-11 03:49:52.351974: Validation complete 
2025-03-11 03:49:52.352158: Mean Validation Dice:  0.5492022229741084 
