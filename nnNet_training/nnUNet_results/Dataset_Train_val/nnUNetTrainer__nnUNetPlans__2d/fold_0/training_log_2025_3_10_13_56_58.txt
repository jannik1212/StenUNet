
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [7, 7], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset_Train_val', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 512, 512], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 115.30154836509529, 'median': 116.0, 'min': 0.0, 'percentile_00_5': 39.0, 'percentile_99_5': 202.0, 'std': 33.93669307531929}}} 
 
2025-03-10 13:57:00.193272: unpacking dataset... 
2025-03-10 13:57:04.503034: unpacking done... 
2025-03-10 13:57:04.503766: do_dummy_2d_data_aug: False 
2025-03-10 13:57:04.510739: Using splits from existing split file: ./nnNet_training/nnUNet_preprocessed/Dataset_Train_val/splits_final.json 
2025-03-10 13:57:04.511698: The split file contains 5 splits. 
2025-03-10 13:57:04.511776: Desired fold for training: 0 
2025-03-10 13:57:04.511840: This split has 800 training and 200 validation cases. 
2025-03-10 13:57:04.526185: Unable to plot network architecture: 
2025-03-10 13:57:04.526337: No module named 'hiddenlayer' 
2025-03-10 13:57:04.538467:  
2025-03-10 13:57:04.538544: Epoch 0 
2025-03-10 13:57:04.538690: Current learning rate: 0.01 
2025-03-10 14:01:36.546304: train_loss 0.0461 
2025-03-10 14:01:36.546619: val_loss -0.105 
2025-03-10 14:01:36.546685: Pseudo dice [np.float32(0.0234)] 
2025-03-10 14:01:36.546773: Epoch time: 272.01 s 
2025-03-10 14:01:36.546846: Yayy! New best EMA pseudo Dice: 0.023399999365210533 
2025-03-10 14:01:37.693574:  
2025-03-10 14:01:37.693749: Epoch 1 
2025-03-10 14:01:37.693884: Current learning rate: 0.00999 
2025-03-10 14:05:48.310559: train_loss -0.2095 
2025-03-10 14:05:48.310935: val_loss -0.2965 
2025-03-10 14:05:48.310997: Pseudo dice [np.float32(0.3736)] 
2025-03-10 14:05:48.311079: Epoch time: 250.62 s 
2025-03-10 14:05:48.311140: Yayy! New best EMA pseudo Dice: 0.058400001376867294 
2025-03-10 14:05:49.653137:  
2025-03-10 14:05:49.653313: Epoch 2 
2025-03-10 14:05:49.653441: Current learning rate: 0.00998 
2025-03-10 14:10:00.267213: train_loss -0.2945 
2025-03-10 14:10:00.267505: val_loss -0.3028 
2025-03-10 14:10:00.267565: Pseudo dice [np.float32(0.3673)] 
2025-03-10 14:10:00.267707: Epoch time: 250.62 s 
2025-03-10 14:10:00.267766: Yayy! New best EMA pseudo Dice: 0.0892999991774559 
2025-03-10 14:10:01.607010:  
2025-03-10 14:10:01.607197: Epoch 3 
2025-03-10 14:10:01.607331: Current learning rate: 0.00998 
2025-03-10 14:14:12.216377: train_loss -0.3436 
2025-03-10 14:14:12.216666: val_loss -0.3639 
2025-03-10 14:14:12.216727: Pseudo dice [np.float32(0.4283)] 
2025-03-10 14:14:12.216807: Epoch time: 250.61 s 
2025-03-10 14:14:12.216871: Yayy! New best EMA pseudo Dice: 0.12319999933242798 
2025-03-10 14:14:13.733194:  
2025-03-10 14:14:13.733389: Epoch 4 
2025-03-10 14:14:13.733525: Current learning rate: 0.00997 
2025-03-10 14:18:24.345185: train_loss -0.3734 
2025-03-10 14:18:24.345474: val_loss -0.3695 
2025-03-10 14:18:24.345532: Pseudo dice [np.float32(0.4291)] 
2025-03-10 14:18:24.345613: Epoch time: 250.61 s 
2025-03-10 14:18:24.345673: Yayy! New best EMA pseudo Dice: 0.15379999577999115 
2025-03-10 14:18:25.681080:  
2025-03-10 14:18:25.681260: Epoch 5 
2025-03-10 14:18:25.681394: Current learning rate: 0.00996 
2025-03-10 14:22:36.294159: train_loss -0.4067 
2025-03-10 14:22:36.294432: val_loss -0.3921 
2025-03-10 14:22:36.294491: Pseudo dice [np.float32(0.4518)] 
2025-03-10 14:22:36.294576: Epoch time: 250.61 s 
2025-03-10 14:22:36.294633: Yayy! New best EMA pseudo Dice: 0.18359999358654022 
2025-03-10 14:22:37.599893:  
2025-03-10 14:22:37.600064: Epoch 6 
2025-03-10 14:22:37.600197: Current learning rate: 0.00995 
2025-03-10 14:26:48.213214: train_loss -0.4355 
2025-03-10 14:26:48.213507: val_loss -0.3935 
2025-03-10 14:26:48.213571: Pseudo dice [np.float32(0.453)] 
2025-03-10 14:26:48.213651: Epoch time: 250.61 s 
2025-03-10 14:26:48.213709: Yayy! New best EMA pseudo Dice: 0.21050000190734863 
2025-03-10 14:26:49.529189:  
2025-03-10 14:26:49.529422: Epoch 7 
2025-03-10 14:26:49.529556: Current learning rate: 0.00995 
2025-03-10 14:31:00.132713: train_loss -0.4483 
2025-03-10 14:31:00.132988: val_loss -0.4393 
2025-03-10 14:31:00.133066: Pseudo dice [np.float32(0.4953)] 
2025-03-10 14:31:00.133148: Epoch time: 250.6 s 
2025-03-10 14:31:00.133209: Yayy! New best EMA pseudo Dice: 0.23899999260902405 
2025-03-10 14:31:01.467271:  
2025-03-10 14:31:01.467476: Epoch 8 
2025-03-10 14:31:01.467618: Current learning rate: 0.00994 
2025-03-10 14:35:12.092070: train_loss -0.4724 
2025-03-10 14:35:12.092362: val_loss -0.4512 
2025-03-10 14:35:12.092422: Pseudo dice [np.float32(0.5076)] 
2025-03-10 14:35:12.092501: Epoch time: 250.63 s 
2025-03-10 14:35:12.092561: Yayy! New best EMA pseudo Dice: 0.26589998602867126 
2025-03-10 14:35:13.432744:  
2025-03-10 14:35:13.432917: Epoch 9 
2025-03-10 14:35:13.433063: Current learning rate: 0.00993 
2025-03-10 14:39:24.054067: train_loss -0.5018 
2025-03-10 14:39:24.054361: val_loss -0.4686 
2025-03-10 14:39:24.054421: Pseudo dice [np.float32(0.5219)] 
2025-03-10 14:39:24.054501: Epoch time: 250.62 s 
2025-03-10 14:39:24.054560: Yayy! New best EMA pseudo Dice: 0.2915000021457672 
2025-03-10 14:39:25.405555:  
2025-03-10 14:39:25.405746: Epoch 10 
2025-03-10 14:39:25.405879: Current learning rate: 0.00992 
2025-03-10 14:43:36.036067: train_loss -0.5194 
2025-03-10 14:43:36.036364: val_loss -0.4397 
2025-03-10 14:43:36.036425: Pseudo dice [np.float32(0.4941)] 
2025-03-10 14:43:36.036510: Epoch time: 250.63 s 
2025-03-10 14:43:36.036570: Yayy! New best EMA pseudo Dice: 0.3116999864578247 
2025-03-10 14:43:37.388460:  
2025-03-10 14:43:37.388659: Epoch 11 
2025-03-10 14:43:37.388798: Current learning rate: 0.00992 
2025-03-10 14:47:48.012187: train_loss -0.5285 
2025-03-10 14:47:48.012475: val_loss -0.4751 
2025-03-10 14:47:48.012540: Pseudo dice [np.float32(0.525)] 
2025-03-10 14:47:48.012623: Epoch time: 250.62 s 
2025-03-10 14:47:48.012683: Yayy! New best EMA pseudo Dice: 0.33309999108314514 
2025-03-10 14:47:49.345793:  
2025-03-10 14:47:49.345983: Epoch 12 
2025-03-10 14:47:49.346118: Current learning rate: 0.00991 
2025-03-10 14:51:59.970616: train_loss -0.5517 
2025-03-10 14:51:59.970915: val_loss -0.4445 
2025-03-10 14:51:59.970978: Pseudo dice [np.float32(0.4997)] 
2025-03-10 14:51:59.971065: Epoch time: 250.63 s 
2025-03-10 14:51:59.971140: Yayy! New best EMA pseudo Dice: 0.349700003862381 
2025-03-10 14:52:01.547313:  
2025-03-10 14:52:01.547513: Epoch 13 
2025-03-10 14:52:01.547650: Current learning rate: 0.0099 
2025-03-10 14:56:12.169921: train_loss -0.5671 
2025-03-10 14:56:12.170219: val_loss -0.4538 
2025-03-10 14:56:12.170280: Pseudo dice [np.float32(0.5058)] 
2025-03-10 14:56:12.170361: Epoch time: 250.62 s 
2025-03-10 14:56:12.170423: Yayy! New best EMA pseudo Dice: 0.3652999997138977 
2025-03-10 14:56:13.514766:  
2025-03-10 14:56:13.514954: Epoch 14 
2025-03-10 14:56:13.515087: Current learning rate: 0.00989 
2025-03-10 15:00:24.132158: train_loss -0.561 
2025-03-10 15:00:24.132457: val_loss -0.4465 
2025-03-10 15:00:24.132520: Pseudo dice [np.float32(0.5023)] 
2025-03-10 15:00:24.132607: Epoch time: 250.62 s 
2025-03-10 15:00:24.132665: Yayy! New best EMA pseudo Dice: 0.3790000081062317 
2025-03-10 15:00:25.480899:  
2025-03-10 15:00:25.481114: Epoch 15 
2025-03-10 15:00:25.481253: Current learning rate: 0.00989 
2025-03-10 15:04:36.114651: train_loss -0.5768 
2025-03-10 15:04:36.114936: val_loss -0.4672 
2025-03-10 15:04:36.114997: Pseudo dice [np.float32(0.5206)] 
2025-03-10 15:04:36.115081: Epoch time: 250.63 s 
2025-03-10 15:04:36.115149: Yayy! New best EMA pseudo Dice: 0.39320001006126404 
2025-03-10 15:04:37.465741:  
2025-03-10 15:04:37.465948: Epoch 16 
2025-03-10 15:04:37.466087: Current learning rate: 0.00988 
2025-03-10 15:08:48.104952: train_loss -0.5681 
2025-03-10 15:08:48.105250: val_loss -0.4692 
2025-03-10 15:08:48.105310: Pseudo dice [np.float32(0.5234)] 
2025-03-10 15:08:48.105395: Epoch time: 250.64 s 
2025-03-10 15:08:48.105454: Yayy! New best EMA pseudo Dice: 0.40619999170303345 
2025-03-10 15:08:49.539609:  
2025-03-10 15:08:49.539810: Epoch 17 
2025-03-10 15:08:49.539946: Current learning rate: 0.00987 
2025-03-10 15:13:00.160649: train_loss -0.5913 
2025-03-10 15:13:00.160946: val_loss -0.4994 
2025-03-10 15:13:00.161021: Pseudo dice [np.float32(0.5523)] 
2025-03-10 15:13:00.161106: Epoch time: 250.62 s 
2025-03-10 15:13:00.161166: Yayy! New best EMA pseudo Dice: 0.42080000042915344 
2025-03-10 15:13:01.509298:  
2025-03-10 15:13:01.509489: Epoch 18 
2025-03-10 15:13:01.509620: Current learning rate: 0.00986 
2025-03-10 15:17:12.144817: train_loss -0.5942 
2025-03-10 15:17:12.145113: val_loss -0.4999 
2025-03-10 15:17:12.145180: Pseudo dice [np.float32(0.5547)] 
2025-03-10 15:17:12.145262: Epoch time: 250.64 s 
2025-03-10 15:17:12.145321: Yayy! New best EMA pseudo Dice: 0.4341999888420105 
2025-03-10 15:17:13.501273:  
2025-03-10 15:17:13.501474: Epoch 19 
2025-03-10 15:17:13.501610: Current learning rate: 0.00986 
2025-03-10 15:21:24.114520: train_loss -0.6101 
2025-03-10 15:21:24.114860: val_loss -0.4818 
2025-03-10 15:21:24.114927: Pseudo dice [np.float32(0.5412)] 
2025-03-10 15:21:24.115006: Epoch time: 250.61 s 
2025-03-10 15:21:24.115072: Yayy! New best EMA pseudo Dice: 0.4449000060558319 
2025-03-10 15:21:25.695739:  
2025-03-10 15:21:25.695925: Epoch 20 
2025-03-10 15:21:25.696063: Current learning rate: 0.00985 
2025-03-10 15:25:36.299734: train_loss -0.6137 
2025-03-10 15:25:36.300010: val_loss -0.4919 
2025-03-10 15:25:36.300070: Pseudo dice [np.float32(0.5414)] 
2025-03-10 15:25:36.300148: Epoch time: 250.61 s 
2025-03-10 15:25:36.300205: Yayy! New best EMA pseudo Dice: 0.4544999897480011 
2025-03-10 15:25:37.659703:  
2025-03-10 15:25:37.659968: Epoch 21 
2025-03-10 15:25:37.660115: Current learning rate: 0.00984 
2025-03-10 15:29:48.290268: train_loss -0.6169 
2025-03-10 15:29:48.290546: val_loss -0.4868 
2025-03-10 15:29:48.290606: Pseudo dice [np.float32(0.5411)] 
2025-03-10 15:29:48.290688: Epoch time: 250.63 s 
2025-03-10 15:29:48.290745: Yayy! New best EMA pseudo Dice: 0.46320000290870667 
2025-03-10 15:29:49.628601:  
2025-03-10 15:29:49.628813: Epoch 22 
2025-03-10 15:29:49.628958: Current learning rate: 0.00983 
2025-03-10 15:34:00.288487: train_loss -0.6239 
2025-03-10 15:34:00.288758: val_loss -0.5082 
2025-03-10 15:34:00.288823: Pseudo dice [np.float32(0.556)] 
2025-03-10 15:34:00.288913: Epoch time: 250.66 s 
2025-03-10 15:34:00.288978: Yayy! New best EMA pseudo Dice: 0.4724999964237213 
2025-03-10 15:34:01.627809:  
2025-03-10 15:34:01.628007: Epoch 23 
2025-03-10 15:34:01.628143: Current learning rate: 0.00983 
2025-03-10 15:38:12.251634: train_loss -0.6345 
2025-03-10 15:38:12.251941: val_loss -0.5159 
2025-03-10 15:38:12.252001: Pseudo dice [np.float32(0.5699)] 
2025-03-10 15:38:12.252090: Epoch time: 250.63 s 
2025-03-10 15:38:12.252148: Yayy! New best EMA pseudo Dice: 0.4821999967098236 
2025-03-10 15:38:13.595279:  
2025-03-10 15:38:13.595465: Epoch 24 
2025-03-10 15:38:13.595600: Current learning rate: 0.00982 
2025-03-10 15:42:24.222294: train_loss -0.6315 
2025-03-10 15:42:24.222588: val_loss -0.4858 
2025-03-10 15:42:24.222648: Pseudo dice [np.float32(0.5401)] 
2025-03-10 15:42:24.222730: Epoch time: 250.63 s 
2025-03-10 15:42:24.222788: Yayy! New best EMA pseudo Dice: 0.4880000054836273 
2025-03-10 15:42:25.559760:  
2025-03-10 15:42:25.560052: Epoch 25 
2025-03-10 15:42:25.560189: Current learning rate: 0.00981 
2025-03-10 15:46:36.194125: train_loss -0.6405 
2025-03-10 15:46:36.194423: val_loss -0.4927 
2025-03-10 15:46:36.194487: Pseudo dice [np.float32(0.5392)] 
2025-03-10 15:46:36.194572: Epoch time: 250.64 s 
2025-03-10 15:46:36.194630: Yayy! New best EMA pseudo Dice: 0.49309998750686646 
2025-03-10 15:46:37.525607:  
2025-03-10 15:46:37.525777: Epoch 26 
2025-03-10 15:46:37.525901: Current learning rate: 0.0098 
2025-03-10 15:50:48.160275: train_loss -0.6431 
2025-03-10 15:50:48.160534: val_loss -0.4985 
2025-03-10 15:50:48.160594: Pseudo dice [np.float32(0.5502)] 
2025-03-10 15:50:48.160675: Epoch time: 250.64 s 
2025-03-10 15:50:48.160732: Yayy! New best EMA pseudo Dice: 0.49880000948905945 
2025-03-10 15:50:49.514688:  
2025-03-10 15:50:49.514852: Epoch 27 
2025-03-10 15:50:49.514977: Current learning rate: 0.0098 
2025-03-10 15:55:00.136549: train_loss -0.6519 
2025-03-10 15:55:00.136852: val_loss -0.5176 
2025-03-10 15:55:00.136911: Pseudo dice [np.float32(0.5697)] 
2025-03-10 15:55:00.136991: Epoch time: 250.62 s 
2025-03-10 15:55:00.137065: Yayy! New best EMA pseudo Dice: 0.5059000253677368 
2025-03-10 15:55:01.479468:  
2025-03-10 15:55:01.479644: Epoch 28 
2025-03-10 15:55:01.479780: Current learning rate: 0.00979 
2025-03-10 15:59:12.142505: train_loss -0.6448 
2025-03-10 15:59:12.142785: val_loss -0.4898 
2025-03-10 15:59:12.142848: Pseudo dice [np.float32(0.5415)] 
2025-03-10 15:59:12.142925: Epoch time: 250.66 s 
2025-03-10 15:59:12.142985: Yayy! New best EMA pseudo Dice: 0.5095000267028809 
2025-03-10 15:59:13.716245:  
2025-03-10 15:59:13.716431: Epoch 29 
2025-03-10 15:59:13.716567: Current learning rate: 0.00978 
2025-03-10 16:03:24.331633: train_loss -0.6467 
2025-03-10 16:03:24.331920: val_loss -0.5198 
2025-03-10 16:03:24.331979: Pseudo dice [np.float32(0.5719)] 
2025-03-10 16:03:24.332060: Epoch time: 250.62 s 
2025-03-10 16:03:24.332120: Yayy! New best EMA pseudo Dice: 0.5156999826431274 
2025-03-10 16:03:25.690904:  
2025-03-10 16:03:25.691095: Epoch 30 
2025-03-10 16:03:25.691226: Current learning rate: 0.00977 
2025-03-10 16:07:36.319739: train_loss -0.6735 
2025-03-10 16:07:36.320035: val_loss -0.5242 
2025-03-10 16:07:36.320096: Pseudo dice [np.float32(0.5742)] 
2025-03-10 16:07:36.320174: Epoch time: 250.63 s 
2025-03-10 16:07:36.320239: Yayy! New best EMA pseudo Dice: 0.5216000080108643 
2025-03-10 16:07:37.670847:  
2025-03-10 16:07:37.671031: Epoch 31 
2025-03-10 16:07:37.671165: Current learning rate: 0.00977 
2025-03-10 16:11:48.302092: train_loss -0.6586 
2025-03-10 16:11:48.302461: val_loss -0.5069 
2025-03-10 16:11:48.302525: Pseudo dice [np.float32(0.5573)] 
2025-03-10 16:11:48.302609: Epoch time: 250.63 s 
2025-03-10 16:11:48.302669: Yayy! New best EMA pseudo Dice: 0.5250999927520752 
2025-03-10 16:11:49.658039:  
2025-03-10 16:11:49.658237: Epoch 32 
2025-03-10 16:11:49.658369: Current learning rate: 0.00976 
2025-03-10 16:16:00.305183: train_loss -0.6596 
2025-03-10 16:16:00.305467: val_loss -0.525 
2025-03-10 16:16:00.305526: Pseudo dice [np.float32(0.5745)] 
2025-03-10 16:16:00.305618: Epoch time: 250.65 s 
2025-03-10 16:16:00.305676: Yayy! New best EMA pseudo Dice: 0.5300999879837036 
2025-03-10 16:16:01.656877:  
2025-03-10 16:16:01.657090: Epoch 33 
2025-03-10 16:16:01.657232: Current learning rate: 0.00975 
2025-03-10 16:20:12.300886: train_loss -0.6764 
2025-03-10 16:20:12.301204: val_loss -0.5139 
2025-03-10 16:20:12.301262: Pseudo dice [np.float32(0.5705)] 
2025-03-10 16:20:12.301339: Epoch time: 250.65 s 
2025-03-10 16:20:12.301398: Yayy! New best EMA pseudo Dice: 0.5340999960899353 
2025-03-10 16:20:13.657275:  
2025-03-10 16:20:13.657484: Epoch 34 
2025-03-10 16:20:13.657628: Current learning rate: 0.00974 
2025-03-10 16:24:24.296376: train_loss -0.6813 
2025-03-10 16:24:24.296755: val_loss -0.5289 
2025-03-10 16:24:24.296820: Pseudo dice [np.float32(0.5816)] 
2025-03-10 16:24:24.296903: Epoch time: 250.64 s 
2025-03-10 16:24:24.296964: Yayy! New best EMA pseudo Dice: 0.5389000177383423 
2025-03-10 16:24:25.684000:  
2025-03-10 16:24:25.684202: Epoch 35 
2025-03-10 16:24:25.684337: Current learning rate: 0.00974 
2025-03-10 16:28:36.307359: train_loss -0.6916 
2025-03-10 16:28:36.307657: val_loss -0.5066 
2025-03-10 16:28:36.307717: Pseudo dice [np.float32(0.557)] 
2025-03-10 16:28:36.307793: Epoch time: 250.62 s 
2025-03-10 16:28:36.307858: Yayy! New best EMA pseudo Dice: 0.5407000184059143 
2025-03-10 16:28:37.870997:  
2025-03-10 16:28:37.871176: Epoch 36 
2025-03-10 16:28:37.871303: Current learning rate: 0.00973 
2025-03-10 16:32:48.508202: train_loss -0.6785 
2025-03-10 16:32:48.508509: val_loss -0.4989 
2025-03-10 16:32:48.508573: Pseudo dice [np.float32(0.5526)] 
2025-03-10 16:32:48.508659: Epoch time: 250.64 s 
2025-03-10 16:32:48.508721: Yayy! New best EMA pseudo Dice: 0.5418999791145325 
2025-03-10 16:32:50.106035:  
2025-03-10 16:32:50.106230: Epoch 37 
2025-03-10 16:32:50.106364: Current learning rate: 0.00972 
2025-03-10 16:37:00.756299: train_loss -0.697 
2025-03-10 16:37:00.756663: val_loss -0.5196 
2025-03-10 16:37:00.756722: Pseudo dice [np.float32(0.5706)] 
2025-03-10 16:37:00.756800: Epoch time: 250.65 s 
2025-03-10 16:37:00.756857: Yayy! New best EMA pseudo Dice: 0.544700026512146 
2025-03-10 16:37:02.131473:  
2025-03-10 16:37:02.131645: Epoch 38 
2025-03-10 16:37:02.131779: Current learning rate: 0.00971 
2025-03-10 16:41:12.785462: train_loss -0.6883 
2025-03-10 16:41:12.785981: val_loss -0.5337 
2025-03-10 16:41:12.786044: Pseudo dice [np.float32(0.5824)] 
2025-03-10 16:41:12.786165: Epoch time: 250.66 s 
2025-03-10 16:41:12.786252: Yayy! New best EMA pseudo Dice: 0.5485000014305115 
2025-03-10 16:41:14.206988:  
2025-03-10 16:41:14.207193: Epoch 39 
2025-03-10 16:41:14.207301: Current learning rate: 0.00971 
2025-03-10 16:45:24.829716: train_loss -0.698 
2025-03-10 16:45:24.830101: val_loss -0.5017 
2025-03-10 16:45:24.830165: Pseudo dice [np.float32(0.5561)] 
2025-03-10 16:45:24.830239: Epoch time: 250.62 s 
2025-03-10 16:45:24.830295: Yayy! New best EMA pseudo Dice: 0.5493000149726868 
2025-03-10 16:45:26.196841:  
2025-03-10 16:45:26.197066: Epoch 40 
2025-03-10 16:45:26.197170: Current learning rate: 0.0097 
2025-03-10 16:49:36.830653: train_loss -0.6944 
2025-03-10 16:49:36.830900: val_loss -0.5217 
2025-03-10 16:49:36.830956: Pseudo dice [np.float32(0.5711)] 
2025-03-10 16:49:36.831028: Epoch time: 250.64 s 
2025-03-10 16:49:36.831085: Yayy! New best EMA pseudo Dice: 0.5515000224113464 
2025-03-10 16:49:38.231979:  
2025-03-10 16:49:38.232137: Epoch 41 
2025-03-10 16:49:38.232241: Current learning rate: 0.00969 
2025-03-10 16:53:48.873403: train_loss -0.707 
2025-03-10 16:53:48.873668: val_loss -0.4713 
2025-03-10 16:53:48.873786: Pseudo dice [np.float32(0.5191)] 
2025-03-10 16:53:48.873861: Epoch time: 250.64 s 
2025-03-10 16:53:49.777784:  
2025-03-10 16:53:49.777943: Epoch 42 
2025-03-10 16:53:49.778045: Current learning rate: 0.00968 
2025-03-10 16:58:00.417044: train_loss -0.7013 
2025-03-10 16:58:00.417291: val_loss -0.5142 
2025-03-10 16:58:00.417356: Pseudo dice [np.float32(0.5645)] 
2025-03-10 16:58:00.417440: Epoch time: 250.64 s 
2025-03-10 16:58:01.320343:  
2025-03-10 16:58:01.320513: Epoch 43 
2025-03-10 16:58:01.320616: Current learning rate: 0.00968 
2025-03-10 17:02:11.960112: train_loss -0.6943 
2025-03-10 17:02:11.960384: val_loss -0.5163 
2025-03-10 17:02:11.960447: Pseudo dice [np.float32(0.5663)] 
2025-03-10 17:02:11.960519: Epoch time: 250.64 s 
2025-03-10 17:02:11.960579: Yayy! New best EMA pseudo Dice: 0.5515000224113464 
2025-03-10 17:02:13.669959:  
2025-03-10 17:02:13.670124: Epoch 44 
2025-03-10 17:02:13.670233: Current learning rate: 0.00967 
2025-03-10 17:06:24.303066: train_loss -0.6913 
2025-03-10 17:06:24.303325: val_loss -0.5176 
2025-03-10 17:06:24.303382: Pseudo dice [np.float32(0.568)] 
2025-03-10 17:06:24.303455: Epoch time: 250.63 s 
2025-03-10 17:06:24.303509: Yayy! New best EMA pseudo Dice: 0.5530999898910522 
2025-03-10 17:06:25.654479:  
2025-03-10 17:06:25.654651: Epoch 45 
2025-03-10 17:06:25.654755: Current learning rate: 0.00966 
2025-03-10 17:10:36.305045: train_loss -0.6972 
2025-03-10 17:10:36.305328: val_loss -0.5422 
2025-03-10 17:10:36.305385: Pseudo dice [np.float32(0.591)] 
2025-03-10 17:10:36.305457: Epoch time: 250.65 s 
2025-03-10 17:10:36.305520: Yayy! New best EMA pseudo Dice: 0.5569000244140625 
2025-03-10 17:10:37.658279:  
2025-03-10 17:10:37.658425: Epoch 46 
2025-03-10 17:10:37.658530: Current learning rate: 0.00965 
2025-03-10 17:14:48.300633: train_loss -0.7042 
2025-03-10 17:14:48.300887: val_loss -0.5295 
2025-03-10 17:14:48.300944: Pseudo dice [np.float32(0.5809)] 
2025-03-10 17:14:48.301028: Epoch time: 250.64 s 
2025-03-10 17:14:48.301090: Yayy! New best EMA pseudo Dice: 0.5593000054359436 
2025-03-10 17:14:49.659042:  
2025-03-10 17:14:49.659204: Epoch 47 
2025-03-10 17:14:49.659312: Current learning rate: 0.00965 
2025-03-10 17:19:00.310709: train_loss -0.7028 
2025-03-10 17:19:00.311001: val_loss -0.5209 
2025-03-10 17:19:00.311058: Pseudo dice [np.float32(0.569)] 
2025-03-10 17:19:00.311139: Epoch time: 250.65 s 
2025-03-10 17:19:00.311194: Yayy! New best EMA pseudo Dice: 0.5602999925613403 
2025-03-10 17:19:01.677553:  
2025-03-10 17:19:01.677712: Epoch 48 
2025-03-10 17:19:01.677817: Current learning rate: 0.00964 
2025-03-10 17:23:12.309840: train_loss -0.7111 
2025-03-10 17:23:12.310102: val_loss -0.5143 
2025-03-10 17:23:12.310163: Pseudo dice [np.float32(0.5677)] 
2025-03-10 17:23:12.310242: Epoch time: 250.63 s 
2025-03-10 17:23:12.310311: Yayy! New best EMA pseudo Dice: 0.5609999895095825 
2025-03-10 17:23:13.679683:  
2025-03-10 17:23:13.679851: Epoch 49 
2025-03-10 17:23:13.679967: Current learning rate: 0.00963 
2025-03-10 17:27:24.336056: train_loss -0.7113 
2025-03-10 17:27:24.336343: val_loss -0.5186 
2025-03-10 17:27:24.336406: Pseudo dice [np.float32(0.5672)] 
2025-03-10 17:27:24.336501: Epoch time: 250.66 s 
2025-03-10 17:27:24.720246: Yayy! New best EMA pseudo Dice: 0.5616000294685364 
2025-03-10 17:27:26.114335:  
2025-03-10 17:27:26.114529: Epoch 50 
2025-03-10 17:27:26.114665: Current learning rate: 0.00962 
2025-03-10 17:31:36.751491: train_loss -0.7173 
2025-03-10 17:31:36.752074: val_loss -0.5343 
2025-03-10 17:31:36.752135: Pseudo dice [np.float32(0.5801)] 
2025-03-10 17:31:36.752265: Epoch time: 250.64 s 
2025-03-10 17:31:36.752331: Yayy! New best EMA pseudo Dice: 0.5634999871253967 
2025-03-10 17:31:38.145676:  
2025-03-10 17:31:38.145921: Epoch 51 
2025-03-10 17:31:38.146051: Current learning rate: 0.00962 
2025-03-10 17:35:48.765694: train_loss -0.7107 
2025-03-10 17:35:48.766051: val_loss -0.5178 
2025-03-10 17:35:48.766133: Pseudo dice [np.float32(0.5655)] 
2025-03-10 17:35:48.766217: Epoch time: 250.62 s 
2025-03-10 17:35:48.766287: Yayy! New best EMA pseudo Dice: 0.5637000203132629 
2025-03-10 17:35:50.481786:  
2025-03-10 17:35:50.481990: Epoch 52 
2025-03-10 17:35:50.482132: Current learning rate: 0.00961 
2025-03-10 17:40:01.117217: train_loss -0.7119 
2025-03-10 17:40:01.117527: val_loss -0.5325 
2025-03-10 17:40:01.117597: Pseudo dice [np.float32(0.5764)] 
2025-03-10 17:40:01.117680: Epoch time: 250.64 s 
2025-03-10 17:40:01.117760: Yayy! New best EMA pseudo Dice: 0.5649999976158142 
2025-03-10 17:40:02.449272:  
2025-03-10 17:40:02.449453: Epoch 53 
2025-03-10 17:40:02.449588: Current learning rate: 0.0096 
2025-03-10 17:44:13.090933: train_loss -0.7239 
2025-03-10 17:44:13.091243: val_loss -0.5384 
2025-03-10 17:44:13.091304: Pseudo dice [np.float32(0.5863)] 
2025-03-10 17:44:13.091387: Epoch time: 250.64 s 
2025-03-10 17:44:13.091445: Yayy! New best EMA pseudo Dice: 0.5670999884605408 
2025-03-10 17:44:14.431304:  
2025-03-10 17:44:14.431514: Epoch 54 
2025-03-10 17:44:14.431655: Current learning rate: 0.00959 
2025-03-10 17:48:25.069462: train_loss -0.7223 
2025-03-10 17:48:25.069822: val_loss -0.5113 
2025-03-10 17:48:25.069883: Pseudo dice [np.float32(0.5595)] 
2025-03-10 17:48:25.069960: Epoch time: 250.64 s 
2025-03-10 17:48:25.980863:  
2025-03-10 17:48:25.981084: Epoch 55 
2025-03-10 17:48:25.981224: Current learning rate: 0.00959 
2025-03-10 17:52:36.593412: train_loss -0.7202 
2025-03-10 17:52:36.594132: val_loss -0.5376 
2025-03-10 17:52:36.594194: Pseudo dice [np.float32(0.583)] 
2025-03-10 17:52:36.594274: Epoch time: 250.61 s 
2025-03-10 17:52:36.594331: Yayy! New best EMA pseudo Dice: 0.5680000185966492 
2025-03-10 17:52:37.930860:  
2025-03-10 17:52:37.931039: Epoch 56 
2025-03-10 17:52:37.931167: Current learning rate: 0.00958 
2025-03-10 17:56:48.558857: train_loss -0.7176 
2025-03-10 17:56:48.559154: val_loss -0.5206 
2025-03-10 17:56:48.559218: Pseudo dice [np.float32(0.5679)] 
2025-03-10 17:56:48.559299: Epoch time: 250.63 s 
2025-03-10 17:56:49.460390:  
2025-03-10 17:56:49.460575: Epoch 57 
2025-03-10 17:56:49.460701: Current learning rate: 0.00957 
2025-03-10 18:01:00.065699: train_loss -0.7262 
2025-03-10 18:01:00.065991: val_loss -0.531 
2025-03-10 18:01:00.066056: Pseudo dice [np.float32(0.5767)] 
2025-03-10 18:01:00.066138: Epoch time: 250.61 s 
2025-03-10 18:01:00.066199: Yayy! New best EMA pseudo Dice: 0.5688999891281128 
2025-03-10 18:01:01.411809:  
2025-03-10 18:01:01.411975: Epoch 58 
2025-03-10 18:01:01.412107: Current learning rate: 0.00956 
2025-03-10 18:05:12.024816: train_loss -0.7224 
2025-03-10 18:05:12.025104: val_loss -0.5166 
2025-03-10 18:05:12.025168: Pseudo dice [np.float32(0.5709)] 
2025-03-10 18:05:12.025254: Epoch time: 250.61 s 
2025-03-10 18:05:12.025318: Yayy! New best EMA pseudo Dice: 0.569100022315979 
2025-03-10 18:05:13.378045:  
2025-03-10 18:05:13.378231: Epoch 59 
2025-03-10 18:05:13.378369: Current learning rate: 0.00956 
2025-03-10 18:09:23.991349: train_loss -0.7299 
2025-03-10 18:09:23.991687: val_loss -0.5308 
2025-03-10 18:09:23.991746: Pseudo dice [np.float32(0.5785)] 
2025-03-10 18:09:23.991825: Epoch time: 250.61 s 
2025-03-10 18:09:23.991885: Yayy! New best EMA pseudo Dice: 0.5699999928474426 
2025-03-10 18:09:25.667688:  
2025-03-10 18:09:25.667879: Epoch 60 
2025-03-10 18:09:25.668015: Current learning rate: 0.00955 
2025-03-10 18:13:36.303587: train_loss -0.738 
2025-03-10 18:13:36.303843: val_loss -0.514 
2025-03-10 18:13:36.303905: Pseudo dice [np.float32(0.5669)] 
2025-03-10 18:13:36.303981: Epoch time: 250.64 s 
2025-03-10 18:13:37.229020:  
2025-03-10 18:13:37.229214: Epoch 61 
2025-03-10 18:13:37.229351: Current learning rate: 0.00954 
2025-03-10 18:17:47.871032: train_loss -0.7226 
2025-03-10 18:17:47.871341: val_loss -0.4951 
2025-03-10 18:17:47.871403: Pseudo dice [np.float32(0.5463)] 
2025-03-10 18:17:47.871487: Epoch time: 250.64 s 
2025-03-10 18:17:48.785419:  
2025-03-10 18:17:48.785603: Epoch 62 
2025-03-10 18:17:48.785726: Current learning rate: 0.00953 
